---
name: cn-llm
description: "**China LLM Gateway**  
â€”â€”ä¸€ä¸ªç»Ÿä¸€çš„ä¸­å›½å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥å£ï¼Œæ”¯æŒ Qwenã€DeepSeekã€GLMã€Baichuan ç­‰æ¨¡å‹ã€‚å…¼å®¹ OpenAIï¼Œåªéœ€ä¸€ä¸ª API å¯†é’¥å³å¯ä½¿ç”¨æ‰€æœ‰æ¨¡å‹ã€‚"
homepage: https://openclaw.ai
metadata: {"openclaw":{"emoji":"ğŸ‰","requires":{"bins":["curl","python3"],"env":["AISA_API_KEY"]},"primaryEnv":"AISA_API_KEY"}}
---

# OpenClaw CN-LLM ğŸ‰  
**ä¸­å›½å¤§è¯­è¨€æ¨¡å‹ç»Ÿä¸€å…¥å£ã€‚ç”±AIsaæä¾›æ”¯æŒã€‚**  

åªéœ€ä¸€ä¸ªAPIå¯†é’¥ï¼Œå³å¯è®¿é—®æ‰€æœ‰ä¸­å›½çš„å¤§è¯­è¨€æ¨¡å‹ã€‚æ”¯æŒOpenAIæ¥å£ã€‚  
Qwenã€DeepSeekã€GLMã€Baichuanã€Moonshotç­‰æ¨¡å‹ï¼Œå‡å¯é€šè¿‡ç»Ÿä¸€çš„APIè¿›è¡Œè®¿é—®ã€‚  

## ğŸ”¥ æ‚¨å¯ä»¥åšä»€ä¹ˆ  

### æ™ºèƒ½èŠå¤©  
```
"Use Qwen to answer Chinese questions, use DeepSeek for coding"
```  

### æ·±åº¦æ¨ç†  
```
"Use DeepSeek-R1 for complex reasoning tasks"
```  

### ä»£ç ç”Ÿæˆ  
```
"Use DeepSeek-Coder to generate Python code with explanations"
```  

### é•¿æ–‡æœ¬å¤„ç†  
```
"Use Qwen-Long for ultra-long document summarization"
```  

### æ¨¡å‹æ¯”è¾ƒ  
```
"Compare response quality between Qwen-Max and DeepSeek-V3"
```  

## æ”¯æŒçš„æ¨¡å‹  

### Qwenï¼ˆé˜¿é‡Œå·´å·´ï¼‰  

| æ¨¡å‹ | è¾“å…¥ä»·æ ¼ï¼ˆç™¾ä¸‡ä»¤ç‰Œï¼‰ | è¾“å‡ºä»·æ ¼ï¼ˆç™¾ä¸‡ä»¤ç‰Œï¼‰ | ç‰¹ç‚¹ |
|-----|---------|---------|------|  
| qwen3-max | $1.37/M | $5.48/M | æœ€å¼ºå¤§çš„é€šç”¨æ¨¡å‹ |
| qwen3-max-2026-01-23 | $1.37/M | $5.48/M | æœ€æ–°ç‰ˆæœ¬ |
| qwen3-coder-plus | $2.86/M | $28.60/M | å¼ºåŒ–çš„ä»£ç ç”ŸæˆåŠŸèƒ½ |
| qwen3-coder-flash | $0.72/M | $3.60/M | å¿«é€Ÿä»£ç ç”Ÿæˆ |
| qwen3-coder-480b-a35b-instruct | $2.15/M | $8.60/M | 480Bå¤§å‹æ¨¡å‹ |
| qwen3-vl-plus | $0.43/M | $4.30/M | è§†è§‰è¯­è¨€æ¨¡å‹ |
| qwen3-vl-flash | $0.86/M | $0.86/M | å¿«é€Ÿè§†è§‰æ¨¡å‹ |
| qwen3-omni-flash | $4.00/M | $16.00/M | å¤šæ¨¡æ€æ¨¡å‹ |
| qwen-vl-max | $0.23/M | $0.57/M | è§†è§‰è¯­è¨€æ¨¡å‹ |
| qwen-plus-2025-12-01 | $1.26/M | $12.60/M | å‡çº§ç‰ˆæœ¬ |
| qwen-mt-flash | $0.168/M | $0.514/M | å¿«é€Ÿæœºå™¨ç¿»è¯‘ |
| qwen-mt-lite | $0.13/M | $0.39/M | ç®€æ˜“æœºå™¨ç¿»è¯‘ |

### DeepSeek  

| æ¨¡å‹ | è¾“å…¥ä»·æ ¼ï¼ˆç™¾ä¸‡ä»¤ç‰Œï¼‰ | è¾“å‡ºä»·æ ¼ï¼ˆç™¾ä¸‡ä»¤ç‰Œï¼‰ | ç‰¹ç‚¹ |
|-----|---------|---------|------|  
| deepseek-r1 | $2.00/M | $8.00/M | æ¨ç†æ¨¡å‹ï¼Œæ”¯æŒå·¥å…·ä½¿ç”¨ |
| deepseek-v3 | $1.00/M | $4.00/M | é€šç”¨èŠå¤©æ¨¡å‹ï¼Œå‚æ•°é‡671B |
| deepseek-v3-0324 | $1.20/M | $4.80/M | V3ç¨³å®šç‰ˆæœ¬ |
| deepseek-v3.1 | $4.00/M | $12.00/M | æœ€æ–°Terminusç‰ˆæœ¬ |

> **æ³¨æ„**ï¼šä»·æ ¼ä»¥ç™¾ä¸‡ä»¤ç‰Œï¼ˆMï¼‰ä¸ºå•ä½ã€‚æ¨¡å‹å¯ç”¨æ€§å¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ï¼Œè¯·è®¿é—®[marketplace.aisa.one/pricing](https://marketplace.aisa.one/pricing)è·å–æœ€æ–°åˆ—è¡¨ã€‚  

## å¿«é€Ÿå…¥é—¨  
```bash
export AISA_API_KEY="your-key"
```  

## APIç«¯ç‚¹  
```
POST https://api.aisa.one/v1/chat/completions
```  

### å…¼å®¹OpenAIçš„æ¥å£  
```bash
curl -X POST "https://api.aisa.one/v1/chat/completions" \
  -H "Authorization: Bearer $AISA_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen3-max",
    "messages": [
      {"role": "system", "content": "You are a professional Chinese assistant."},
      {"role": "user", "content": "Please explain what a large language model is?"}
    ],
    "temperature": 0.7,
    "max_tokens": 1000
  }'
```  

#### Qwenç¤ºä¾‹  
```bash
# DeepSeek-V3 general chat (671B parameters)
curl -X POST "https://api.aisa.one/v1/chat/completions" \
  -H "Authorization: Bearer $AISA_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-v3",
    "messages": [{"role": "user", "content": "Write a quicksort algorithm in Python"}],
    "temperature": 0.3
  }'

# DeepSeek-R1 deep reasoning (supports Tools)
curl -X POST "https://api.aisa.one/v1/chat/completions" \
  -H "Authorization: Bearer $AISA_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-r1",
    "messages": [{"role": "user", "content": "A farmer needs to cross a river with a wolf, a sheep, and a cabbage. The boat can only carry the farmer and one item at a time. If the farmer is not present, the wolf will eat the sheep, and the sheep will eat the cabbage. How can the farmer safely cross?"}]
  }'

# DeepSeek-V3.1 Terminus latest version
curl -X POST "https://api.aisa.one/v1/chat/completions" \
  -H "Authorization: Bearer $AISA_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-v3.1",
    "messages": [{"role": "user", "content": "Implement an LRU cache with get and put operations"}]
  }'
```  

#### DeepSeekç¤ºä¾‹  
```bash
curl -X POST "https://api.aisa.one/v1/chat/completions" \
  -H "Authorization: Bearer $AISA_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen3-coder-plus",
    "messages": [{"role": "user", "content": "Implement a thread-safe Map in Go"}]
  }'
```  

#### Qwen3ä»£ç ç”Ÿæˆç¤ºä¾‹  
```json
{
  "id": "chatcmpl-xxx",
  "object": "chat.completion",
  "created": 1234567890,
  "model": "qwen-max",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "A large language model (LLM) is a deep learning-based..."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 30,
    "completion_tokens": 150,
    "total_tokens": 180,
    "cost": 0.001
  }
}
```  

#### å‚æ•°å‚è€ƒ  
| å‚æ•° | ç±»å‹ | æ˜¯å¦å¿…å¡« | è¯´æ˜ |
|-----|------|-----|------|  
| `model` | string | æ˜¯ | æ¨¡å‹æ ‡è¯†ç¬¦ |
| `messages` | array | æ˜¯ | æ¶ˆæ¯åˆ—è¡¨ |
| `temperature` | number | å¦ | éšæœºæ€§ï¼ˆ0-2ï¼Œé»˜è®¤1ï¼‰ |
| `max_tokens` | integer | å¦ | ç”Ÿæˆçš„æœ€å¤§ä»¤ç‰Œæ•° |
| `stream` | boolean | å¦ | æµå¼è¾“å‡ºï¼ˆé»˜è®¤ä¸ºfalseï¼‰ |
| `top_p` | number | å¦ | æ ¸å¿ƒé‡‡æ ·å‚æ•°ï¼ˆ0-1ï¼‰ |

#### å“åº”æ ¼å¼  
```bash
curl -X POST "https://api.aisa.one/v1/chat/completions" \
  -H "Authorization: Bearer $AISA_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen-plus",
    "messages": [{"role": "user", "content": "Tell a Chinese folk story"}],
    "stream": true
  }'
```  

### æµå¼è¾“å‡º  
```
data: {"id":"chatcmpl-xxx","choices":[{"delta":{"content":"Once"}}]}
data: {"id":"chatcmpl-xxx","choices":[{"delta":{"content":" upon"}}]}
...
data: [DONE]
```  
è¿”å›æœåŠ¡å™¨å‘é€çš„äº‹ä»¶ï¼ˆSSEï¼‰æ ¼å¼ï¼š  

```bash
# Qwen chat
python3 {baseDir}/scripts/cn_llm_client.py chat --model qwen3-max --message "Hello, please introduce yourself"

# Qwen3 code generation
python3 {baseDir}/scripts/cn_llm_client.py chat --model qwen3-coder-plus --message "Write a binary search algorithm"

# DeepSeek-R1 reasoning
python3 {baseDir}/scripts/cn_llm_client.py chat --model deepseek-r1 --message "Which is larger, 9.9 or 9.11? Please reason in detail"

# DeepSeek-V3 chat
python3 {baseDir}/scripts/cn_llm_client.py chat --model deepseek-v3 --message "Tell a story" --stream

# With system prompt
python3 {baseDir}/scripts/cn_llm_client.py chat --model qwen3-max --system "You are a classical poetry expert" --message "Write a poem about plum blossoms"

# Model comparison
python3 {baseDir}/scripts/cn_llm_client.py compare --models "qwen3-max,deepseek-v3" --message "What is quantum computing?"

# List supported models
python3 {baseDir}/scripts/cn_llm_client.py models
```  

## Pythonå®¢æˆ·ç«¯  
```python
from cn_llm_client import CNLLMClient

client = CNLLMClient()  # Uses AISA_API_KEY environment variable

# Qwen chat
response = client.chat(
    model="qwen3-max",
    messages=[{"role": "user", "content": "Hello!"}]
)
print(response["choices"][0]["message"]["content"])

# Qwen3 code generation
response = client.chat(
    model="qwen3-coder-plus",
    messages=[
        {"role": "system", "content": "You are a professional programmer."},
        {"role": "user", "content": "Implement a singleton pattern in Python"}
    ],
    temperature=0.3
)

# Streaming output
for chunk in client.chat_stream(
    model="deepseek-v3",
    messages=[{"role": "user", "content": "Tell a story about an idiom"}]
):
    print(chunk, end="", flush=True)

# Model comparison
results = client.compare_models(
    models=["qwen3-max", "deepseek-v3", "deepseek-r1"],
    message="Explain what machine learning is"
)
for model, result in results.items():
    print(f"{model}: {result['response'][:100]}...")
```  

## CLIä½¿ç”¨  
```python
# Copywriting
response = client.chat(
    model="qwen3-max",
    messages=[
        {"role": "system", "content": "You are a professional copywriter."},
        {"role": "user", "content": "Write a product introduction for a smart watch"}
    ]
)
```  

## Python SDKä½¿ç”¨  
```python
# Code generation and explanation
response = client.chat(
    model="qwen3-coder-plus",
    messages=[{"role": "user", "content": "Implement a thread-safe Map in Go"}]
)
```  

## ä½¿ç”¨åœºæ™¯  

### 1. ä¸­æ–‡å†…å®¹ç”Ÿæˆ  
```python
# Mathematical reasoning
response = client.chat(
    model="deepseek-r1",
    messages=[{"role": "user", "content": "Prove: For any positive integer n, nÂ³-n is divisible by 6"}]
)
```  

### 2. ä»£ç å¼€å‘  
```python
# Image understanding
response = client.chat(
    model="qwen3-vl-plus",
    messages=[
        {"role": "user", "content": [
            {"type": "text", "text": "Describe the content of this image"},
            {"type": "image_url", "image_url": {"url": "https://example.com/image.jpg"}}
        ]}
    ]
)
```  

### 3. å¤æ‚æ¨ç†  
```python
MODEL_MAP = {
    "chat": "qwen3-max",           # General chat
    "code": "qwen3-coder-plus",    # Code generation
    "reasoning": "deepseek-r1",    # Complex reasoning
    "vision": "qwen3-vl-plus",     # Visual understanding
    "fast": "qwen3-coder-flash",   # Fast response
    "translate": "qwen-mt-flash"   # Machine translation
}

def route_by_task(task_type: str, message: str) -> str:
    model = MODEL_MAP.get(task_type, "qwen3-max")
    return client.chat(model=model, messages=[{"role": "user", "content": message}])
```  

### 4. è§†è§‰ç†è§£  
```json
{
  "error": {
    "code": "model_not_found",
    "message": "Model 'xxx' is not available"
  }
}
```  

### 5. æ¨¡å‹è·¯ç”±ç­–ç•¥  
___CODE_BLOCK_21___  

## é”™è¯¯å¤„ç†  
é”™è¯¯ä¼šä»¥JSONæ ¼å¼è¿”å›ï¼Œå…¶ä¸­åŒ…å«`error`å­—æ®µï¼š  
___CODE_BLOCK_22___  
å¸¸è§é”™è¯¯ä»£ç ï¼š  
- `401` - APIå¯†é’¥æ— æ•ˆæˆ–ç¼ºå¤±  
- `402` - è´¦æˆ·ä½™é¢ä¸è¶³  
- `404` - æ¨¡å‹æœªæ‰¾åˆ°  
- `429` - è¶…è¿‡è¯·æ±‚é¢‘ç‡é™åˆ¶  
- `500` - æœåŠ¡å™¨é”™è¯¯  

## ä»·æ ¼  
| æ¨¡å‹ | è¾“å…¥ä»·æ ¼ï¼ˆç™¾ä¸‡ä»¤ç‰Œï¼‰ | è¾“å‡ºä»·æ ¼ï¼ˆç™¾ä¸‡ä»¤ç‰Œï¼‰ |
|-----|-----------|-----------|  
| qwen3-max | $1.37 | $5.48 |
| qwen3-coder-plus | $2.86 | $28.60 |
| qwen3-coder-flash | $0.72 | $3.60 |
| qwen3-vl-plus | $0.43 | $4.30 |
| deepseek-v3 | $1.00 | $4.00 |
| deepseek-r1 | $2.00 | $8.00 |
| deepseek-v3.1 | $4.00 | $12.00 |

> ä»·æ ¼å•ä½ï¼šæ¯ç™¾ä¸‡ä»¤ç‰Œï¼ˆ$ï¼‰ã€‚æ¯ä¸ªå“åº”åŒ…å«`usage.cost`å’Œ`usage.credits_remaining`ä¿¡æ¯ã€‚  

## å¼€å§‹ä½¿ç”¨  
1. åœ¨[aisa.one](https://aisa.one)æ³¨å†Œ  
2. è·å–APIå¯†é’¥  
3. å……å€¼ï¼ˆæŒ‰éœ€ä»˜è´¹ï¼‰  
4. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š`export AISA_API_KEY="your-key"`  

## å®Œæ•´APIå‚è€ƒ  
è¯·å‚é˜…[APIå‚è€ƒ](https://aisa.mintlify.app/api-reference/introduction)ä»¥è·å–å®Œæ•´çš„ç«¯ç‚¹æ–‡æ¡£ã€‚