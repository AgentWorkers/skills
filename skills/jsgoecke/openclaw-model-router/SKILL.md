---
name: model-router
description: 智能的、基于成本意识的模型路由系统：该系统能够根据任务的复杂性自动选择最合适的AI模型。简单任务会被自动路由到成本较低的模型，而复杂任务则会分配给性能更优的模型。适用于需要解决“应该使用哪个模型？”、“如何为任务选择合适的模型？”、“如何优化成本？”、“如何在不同模型之间切换？”等问题，同时也适用于需要在多个AI服务提供商之间平衡质量与成本的需求。系统支持逐步升级的路由策略（即根据任务需求逐步提升模型复杂度），采用五层级的路由机制，并实时显示当前模型的定价信息。
version: 2.0.0
---
# 智能模型路由器

**为 OpenClaw 代理提供智能且成本敏感的模型路由服务。**

在使用 `sessions_spawn` 执行任何任务或委托给子代理之前，根据以下规则对任务复杂性进行分类，并将任务路由到最合适的模型。通过为简单任务使用成本较低的模型，为确实需要高级模型的任务保留高级模型，从而节省 60-90% 的大型语言模型（LLM）使用成本。

## 核心原则

**将每个请求路由到能够处理它的最便宜的模型。**

## 第一步：分类任务复杂性

从以下维度对任务进行评分：

### 简单任务（路由到第一层级）
- 问候语、闲聊、状态检查、心跳请求
- 单个事实性问题（“X 是什么？”、“定义 Y”）
- 简单的翻译、格式转换
- 文件查找、目录列表、基本 shell 命令
- 日历查询、天气查询
- 任务长度少于 50 个令牌且没有技术复杂性
- 关键词：什么是、定义、翻译、列表、检查、问候、状态

### 中等复杂度任务（路由到第二层级）
- 文档或对话的总结
- 单个文件的代码编辑、错误修复、简单的重构
- 编写电子邮件、消息、简短内容
- 数据提取、解析、格式化
- 解释概念、回答“如何”类型的问题
- 需要综合多个来源的研究
- 关键词：总结、解释、编写、修复这个、如何、提取

### 复杂任务（路由到第三层级）
- 多个文件的代码生成或重构
- 架构设计、系统设计
- 创意写作（故事、长篇内容、细腻的表达）
- 跨多个系统的复杂问题调试
- 需要多角度分析的任务
- 有约束条件的任务（“在保持 Y 的同时优化 X”）
- 关键词：构建、设计、架构、重构、创建、实现、分析

### 高度复杂度任务（路由到第四层级）
- 数学证明、形式逻辑
- 多步骤推理链（“首先 X，然后 Y，因此 Z”）
- 安全漏洞分析
- 需要权衡的性能优化
- 科学分析、假设检验
- 任何包含“证明”、“推导”、“为什么”、“比较和对比”、“评估权衡”等关键词的任务
- 关键词：证明、推导、推理、为什么、评估

### 特殊规则
- **包含 2 个或更多推理关键词 → 总是路由到第四层级**（高置信度）
- **代码块或多文件引用 → 至少路由到第二层级**
- **“调试” + 堆栈跟踪 → 路由到第三层级**
- **心跳请求和状态检查 → 总是路由到第一层级**
- **不确定时，默认路由到第二层级**（快速、低成本、足够好）

## 第二步：从相应层级中选择模型

### 第零层级 — 免费（OpenRouter 免费层级）
| 模型 | 成本 | 最适合的任务 |
|-------|------|----------|
| Gemini 2.5 Flash（免费） | $0.00 | 高量简单任务、翻译 |
| Gemini 2.5 Flash-Lite（免费） | $0.00 | 翻译、市场营销 |
| Gemini 3 Flash Preview（免费） | $0.00 | 科技、健康、科学 |
| DeepSeek V3.2（免费） | $0.00 | 角色扮演、创意写作 |
| Moonshot Kimi K2.5（免费） | $0.00 | 科技、编程 |
| Arcee Trinity Large Preview（免费） | $0.00 | 创意写作、故事讲述 |

**默认的免费层级模型：`openrouter/free`**（自动从可用的免费模型中选择）

通过 OpenRouter 使用模型 ID 访问，例如 `google/gemini-2.5-flash`、`deepseek/deepseek-v3.2-20251201`、`moonshotai/kimi-k2.5-0127`。或者使用 `openrouter/free` 自动路由到所有免费模型。

**注意：** 免费模型有使用频率限制，且可用性可能不稳定。仅用于非关键任务。

### 第一层级 — 简单任务（接近零成本）
| 模型 | 输入成本（每百万令牌） | 输出成本（每百万令牌） | 最适合的任务 |
|-------|-------------|--------------|----------|
| Gemini 2.0 Flash | $0.10 | $0.40 | 默认的简单层级——快速、多模态、100 万上下文 |
| GPT-4o-mini | $0.15 | $0.60 | 简单任务、多模态 |
| GPT-5 Nano | $0.05 | $0.40 | OpenAI 最便宜的选项 |
| DeepSeek V3 | $0.27 | $1.10 | 经济实惠的通用模型 |
| Gemini 2.5 Flash-Lite | $0.10 | $0.40 | 谷歌最经济的模型 |

**默认的第一层级模型：`gemini-2.0-flash`**（最佳的成本/性能平衡）

### 第二层级 — 中等复杂度任务（平衡性）
| 模型 | 输入成本（每百万令牌） | 输出成本（每百万令牌） | 最适合的任务 |
|-------|-------------|--------------|----------|
| Claude Haiku 4.5 | $1.00 | $5.00 | 接近前沿的模型、快速、优秀的编码能力 |
| GPT-4o | $2.50 | $10.00 | 多模态、工具使用、全面的性能 |
| Gemini 2.5 Flash | $0.15 | $0.60 | 具有思维能力的模型、快速推理 |
| GPT-5 Mini | $0.25 | $2.00 | 性能平衡、40 万上下文 |
| Mistral Medium 3 | $0.40 | $2.00 | 欧洲语言处理能力均衡 |

**默认的第二层级模型：`claude-haiku-4-5`**（该层级中性价比最高的模型）

### 第三层级 — 复杂任务（高级模型）
| 模型 | 输入成本（每百万令牌） | 输出成本（每百万令牌） | 最适合的任务 |
|-------|-------------|--------------|----------|
| Claude Sonnet 4.5 | $3.00 | $15.00 | 最佳的编码性能与成本比 |
| GPT-5 | $1.25 | $10.00 | 领先的编码和代理任务模型 |
| GPT-5.3 Codex | $1.75* | $14.00* | 最强大的代理编码模型 |
| Gemini 2.5 Pro | $1.25 | $10.00 | 编码、推理、支持最多 200 万上下文 |
| Claude Opus 4.5 | $5.00 | $25.00 | 最高的智能水平、适合代理任务 |
| Grok 4 | $3.00 | $15.00 | 前沿的推理能力、实时数据处理 |

*GPT-5.3 Codex 的 API 定价尚未正式发布；根据 GPT-5.2 Codex 的价格估算。*

**默认的第三层级模型：`claude-sonnet-4-5`**（最佳的质量、性能和成本平衡）

### 第四层级 — 高度复杂度任务（最高推理能力）
| 模型 | 输入成本（每百万令牌） | 输出成本（每百万令牌） | 最适合的任务 |
|-------|-------------|--------------|----------|
| Claude Opus 4.6 | $5.00 | $25.00 | 最新的前沿推理模型、扩展的思维能力、100 万上下文（测试版） |
| Claude Opus 4.5 | $5.00 | $25.00 | 扩展的思维能力、前沿推理 |
| o3 | $2.00 | $8.00 | 深度 STEM 领域的推理 |
| DeepSeek R1 | $0.55 | $2.19 | 经济实惠的推理模型（比 o1 便宜 20-50 倍） |
| o4-mini | $1.10 | $4.40 | 高效的推理模型 |

**默认的第四层级模型：`claude-opus-4-6`**（启用扩展思维能力）

## 第三步：应用优化模式

### 🟢 平衡模式（默认模式）
使用上述每个层级的默认模型。如果模型输出质量较低或失败，则升级到下一层级。

### 🔵 激进模式（最大节省）
覆盖层级的默认设置，选择最便宜的选项：
- 第零至第一层级：简单任务使用 `openrouter/free`（$0.00），失败时回退到 `gemini-2.0-flash`（$0.10/$0.40）
- 第二层级：`gemini-2.5-flash`（$0.15/$0.60）
- 第三层级：`gemini-2.5-pro`（$1.25/$10.00）
- 第四层级：`deepseek-r1`（$0.55/$2.19）

**节省：与始终使用最高层级模型相比可节省 70-99% 的成本**

### 🟡 高质量模式（最高质量）
覆盖层级的默认设置，选择同类模型中最好的：
- 第一层级：`claude-haiku-4-5`（$1.00/$5.00）
- 第二层级：`claude-sonnet-4-5`（$3.00/$15.00）
- 第三层级：`claude-opus-4-6`（$5.00/$25.00）或 `gpt-5.3-codex`（用于编码）
- 第四层级：`claude-opus-4-6`（$5.00/$25.00）（启用扩展思维能力）

## 第四步：使用 `sessions_spawn` 执行任务

```bash
# Simple task — Tier 1
sessions_spawn --task "What's on my calendar today?" --model gemini-2.0-flash

# Moderate task — Tier 2
sessions_spawn --task "Summarize this document" --model claude-haiku-4-5

# Complex task — Tier 3
sessions_spawn --task "Build a React auth component with tests" --model claude-sonnet-4-5

# Reasoning task — Tier 4
sessions_spawn --task "Prove this algorithm is O(n log n)" --model claude-opus-4-6
```

## 逐步升级策略

当对任务复杂性不确定时，从低成本模型开始，逐步升级：

```bash
# 1. Try Tier 1 with timeout
sessions_spawn --task "Fix this bug" --model gemini-2.0-flash --runTimeoutSeconds 60

# 2. If output is poor or times out, escalate to Tier 2
sessions_spawn --task "Fix this bug" --model claude-haiku-4-5

# 3. If still failing, escalate to Tier 3
sessions_spawn --task "Fix this complex bug" --model claude-sonnet-4-5
```

最大升级次数：3 次。如果第三层级模型失败，直接向用户显示错误信息，而不是继续消耗令牌。

## 批量任务的并行处理

将批量/并行任务路由到第一层级模型以节省大量成本：

```bash
# Batch summaries in parallel with cheap model
sessions_spawn --task "Summarize doc A" --model gemini-2.0-flash &
sessions_spawn --task "Summarize doc B" --model gemini-2.0-flash &
sessions_spawn --task "Summarize doc C" --model gemini-2.0-flash &
wait

# Then analyze results with premium model
sessions_spawn --task "Synthesize findings from all summaries" --model claude-sonnet-4-5
```

## 特殊路由规则

| 场景 | 路由到 | 原因 |
|----------|----------|-----|
| 心跳请求/状态检查 | 第零层级（`openrouter/free`）或第一层级 | 不需要智能处理，节省成本 |
| 视觉/图像分析 | `gemini-2.5-pro` | 最适合多模态处理和大量上下文 |
| 长文本任务（超过 100 万令牌） | `gemini-2.5-pro` 或 `gpt-5` | 支持 100 万至 200 万令牌的上下文 |
| 中文任务 | `deepseek-v3` 或 `glm-4.7` | 专为中文处理优化 |
| 需要实时网页数据 | `grok-4.1-fast` | 内置的网页搜索功能，支持 200 万令牌的上下文 |
| 代理编码任务 | `gpt-5.3-codex` 或 `claude-sonnet-4-5` | 专为代理编码任务设计 |
| 代码生成 | `claude-sonnet-4-5`（最低成本） | 最高的代码质量 |
| 数学/形式证明 | `o3` 或 `claude-opus-4-6`（支持推理） | 专门用于推理任务的模型 |

## 成本比较（典型工作负载）

对于典型的 OpenClaw 日常工作量（24 次心跳请求 + 20 个子代理任务 + 10 个用户查询）：

| 策略 | 月度成本 | 节省成本 |
|----------|-------------|---------|
| 始终使用最高层级模型（Opus 4.6） | 约 $200 | 基线 |
| 智能路由（平衡模式） | 约 $45 | **节省 78%** |
| 智能路由（激进模式） | 约 $15 | **节省 92%** |
| 智能路由（激进模式 + 免费层级） | 约 $5 | **节省 97%** |
| 始终使用免费模型（OpenRouter） | 约 $0 | **节省 100%**（但受使用频率限制且不可靠） |

## 何时不应降级模型层级

在以下情况下始终使用第三层级及以上模型：
- 对代码安全敏感的审查
- 需要精确计算的金融任务
- 影响整个代码库的架构决策
- 用户明确要求使用高级模型的任务
- 用户要求“彻底处理”或“花时间完成”的任务

## 模式切换

用户可以在对话过程中切换模式：
- “使用激进模式” → 切换到每个层级的最便宜模型 |
- “使用高质量模式” → 切换到每个层级的最佳模型 |
- “使用平衡模式” | 返回到默认设置 |
- “为特定任务使用 [特定模型]” | 为单个任务覆盖路由设置

## 定价参考（2026 年 2 月）

所有价格均为每百万令牌的价格。模型按成本从低到高排序：

| 模型 | 输入成本 | 输出成本 | 上下文容量 | 提供商 |
|-------|-------|--------|---------|----------|
| OpenRouter 免费模型 | $0.00 | $0.00 | 变动 | OpenRouter |
| GPT-5 Nano | $0.05 | $0.40 | 40 万令牌 | OpenAI |
| Gemini 2.0 Flash | $0.10 | $0.40 | 100 万令牌 | Google |
| Gemini 2.5 Flash-Lite | $0.10 | $0.40 | 100 万令牌 | Google |
| GPT-4o-mini | $0.15 | $0.60 | 12.8 万令牌 | OpenAI |
| Gemini 2.5 Flash | $0.15 | $0.60 | 100 万令牌 | Google |
| Grok 4.1 Fast | $0.20 | $0.50 | 20 万令牌 | xAI |
| GPT-5 Mini | $0.25 | $2.00 | 40 万令牌 | OpenAI |
| DeepSeek V3 | $0.27 | $1.10 | 6.4 万令牌 | DeepSeek |
| DeepSeek R1 | $0.55 | $2.19 | 6.4 万令牌 | DeepSeek |
| Claude Haiku 4.5 | $1.00 | $5.00 | 20 万令牌 | Anthropic |
| o4-mini | $1.10 | $4.40 | 20 万令牌 | OpenAI |
| Gemini 2.5 Pro | $1.25 | $10.00 | 100 万令牌 | Google |
| GPT-5 | $1.25 | $10.00 | 40 万令牌 | OpenAI |
| GPT-5.3 Codex | $1.75* | $14.00* | 40 万令牌 | OpenAI |
| o3 | $2.00 | $8.00 | 20 万令牌 | OpenAI |
| GPT-4o | $2.50 | $10.00 | 12.8 万令牌 | OpenAI |
| Claude Sonnet 4.5 | $3.00 | $15.00 | 20 万令牌 | Anthropic |
| Grok 4 | $3.00 | $15.00 | 25.6 万令牌 | xAI |
| Claude Opus 4.5 | $5.00 | $25.00 | 20 万令牌 | Anthropic |
| Claude Opus 4.6 | $5.00 | $25.00 | 20 万令牌（测试版，支持 100 万令牌） | Anthropic |

*GPT-5.3 Codex 的定价基于 GPT-5.2 Codex 的价格估算；官方 API 定价待公布。*

**注意：** 价格可能会变动。请查看提供者的定价页面以获取最新信息。批量 API 使用可享受 50% 的折扣，提示缓存功能可进一步节省 50-90% 的成本。OpenRouter 的免费模型有使用频率限制，请访问 openrouter.ai/collections/free-models 查看当前可用情况。