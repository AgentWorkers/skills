---
name: doubleword-batches
description: 使用 Doubleword API (api.doubleword.ai) 创建和管理批量推理任务。适用于以下场景：  
(1) 批量处理多个 AI 请求；  
(2) 提交 JSONL 格式的批量文件以进行异步推理；  
(3) 监控批量任务的进度并获取结果；  
(4) 与 OpenAI 兼容的批量接口进行交互；  
(5) 处理不需要立即响应的大规模推理工作负载。
---

# 双词批量推理

使用 Doubleword 批量 API 异步处理多个 AI 推理请求。

## 何时使用批量处理

批量处理适用于以下场景：
- 可以同时运行的多个独立请求
- 不需要立即响应的工作负载
- 如果单独发送会超出速率限制的大量请求
- 对成本敏感的工作负载（24 小时时间窗口提供更优惠的价格）

## 快速入门

任何批量作业的基本工作流程如下：
1. **创建 JSONL 文件**，其中每行包含一个请求（每个请求对应一个 JSON 对象）
2. **上传文件** 以获取文件 ID
3. **使用文件 ID 创建批次**
4. **轮询状态** 直到任务完成
5. **从 `output_file_id` 下载结果**

## 工作流程

### 第 1 步：创建批量请求文件

创建一个 `.jsonl` 文件，每行包含一个请求：

**每行所需的字段：**
- `custom_id`：唯一标识符（最多 64 个字符） - 使用描述性 ID（如 `"user-123-question-5"` 以便于结果映射）
- `method`：始终为 `"POST"`
- `url`：始终为 `"/v1/chat/completions"`
- `body`：包含 `model` 和 `messages` 的标准 API 请求

**可选的请求参数：**
- `temperature`：0-2（默认值：1.0）
- `max_tokens`：最大响应令牌数
- `top_p`：Nucleus 采样参数
- `stop`：停止序列

**文件限制：**
- 最大大小：200MB
- 格式：仅支持 JSONL（JSON 行，以换行符分隔）
- 如有必要，可将大型批次拆分为多个文件

**辅助脚本：**
使用 `scripts/create_batch_file.py` 脚本来程序化生成 JSONL 文件：

修改脚本中的 `requests` 列表以生成特定的批量请求。

### 第 2 步：上传文件

上传 JSONL 文件：

响应中包含 `id` 字段 - 保存此文件 ID 以用于后续操作。

### 第 3 步：创建批次

使用文件 ID 创建批次任务：

**参数：**
- `input_file_id`：上传步骤中获得的文件 ID
- `endpoint`：始终为 `"/v1/chat/completions"`
- `completion_window`：选择 `"24h"`（更优惠的价格）或 `"1h"`（价格较高，但结果更快）

响应中包含批次 `id` - 保存此 ID 以用于状态轮询。

### 第 4 步：轮询状态

检查批次进度：

**状态更新：**
1. `validating` - 检查输入文件格式
2. `in_progress` - 正在处理请求
3. `completed` - 所有请求已完成

**其他状态：**
- `failed` - 批次失败（请检查 `error_file_id`）
- `expired` - 批次超时
- `cancelling`/`cancelled` - 批次已取消

**响应内容：**
- `output_file_id`：在此处下载结果
- `error_file_id`：失败的请求（如果有）
- `request_counts`：总请求数/已完成请求数/失败请求数

**轮询频率：** 在处理过程中每 30-60 秒检查一次。

**提前访问：** 在批次完全完成之前，可以通过 `output_file_id` 获取部分结果 - 请查看 `X-Incomplete` 标头。

### 第 5 步：下载结果

下载已完成的结果：

**响应头：**
- `X-Incomplete: true` - 批次仍在处理中，更多结果即将发送
- `X-Last-Line: 45`：部分下载的继续点

**输出格式（每行）：**

**下载错误（如果有）：**

**错误格式（每行）：**

## 其他操作

### 列出所有批次

### 取消批次

### 注意事项：
- 未处理的请求会被取消
- 已经处理的结果仍然可以下载
- 已完成的批次无法取消

## 常见模式

### 处理结果

逐行解析 JSONL 输出：

### 处理部分结果

检查未完成的批次并继续处理：

### 重试失败的请求

从错误文件中提取失败的请求并重新提交：

## 最佳实践：
1. **使用描述性的 `custom_id`**：在 ID 中包含上下文信息，以便于结果映射
   - 示例：`"user-123-question-5"`
   - 不建议的示例：`"1"`、`"req1"`
2. **在上传前本地验证 JSONL 文件**：确保每行都是有效的 JSON 数据
3. **分割大型文件**：保持文件大小在 200MB 以内
4. **选择合适的处理时间窗口**：为了节省成本，选择 `24h`；仅在时间敏感的情况下选择 `1h`
5. **优雅地处理错误**：始终检查 `error_file_id` 并重试失败的请求
6. **监控请求进度**：通过 `completed`/`total` 的比例来跟踪进度
7. **保存文件 ID**：存储批次 ID、输入文件 ID 和输出文件 ID 以供后续查询

## 参考文档

有关完整的 API 详情（包括身份验证、速率限制和高级参数），请参阅：
- **API 参考**：`references/api_reference.md` - 完整的端点文档和模式