# percept-ambient

**环境智能模式** —— 在无需明确指令的情况下实现持续的上下文感知。

## 功能概述

该模式在后台运行，随着时间的推移逐步构建对话、实体及其关系的知识图谱。您的智能助手能够从周围的语音中被动获取上下文信息（例如：与谁交谈、哪些项目正在进行中、做出了哪些决策），而无需用户发出任何指令。

## 使用场景

- 用户希望始终保持上下文感知能力
- 智能助手需要从日常对话中获取背景信息
- 用户根据听到的内容询问：“你对[某人/某项目]了解多少？”

## 系统要求

- 必须安装并运行 **percept-listen** 技能
- 必须安装 **percept-summarize** 技能（用于实体提取）

## 工作原理

1. 所有对话内容都会被持续捕获并汇总
2. 自动提取实体（如人、公司、项目、主题）
3. 自动建立实体之间的关系（例如：属于某个项目、是某个公司的客户、与某个实体共同被提及）
4. 根据需要为智能助手的动作生成相应的上下文数据包
5. 采用全文搜索（FTS5）和向量搜索（LanceDB）技术进行信息检索

## 上下文数据包

当智能助手需要上下文信息时，Percept 会生成一个上下文数据包：

```json
{
  "recent_conversations": [...],
  "resolved_entities": [...],
  "relationships": [...],
  "relevant_history": [...]
}
```

这样，智能助手无需加载完整的对话记录，即可获得丰富的情境感知能力。

## 向量搜索

使用 NVIDIA NIM 嵌入进行语义搜索（为主要方式），并在必要时以 All-MiniLM-L6-v2 作为离线备用方案。所有搜索结果存储在 LanceDB 中（本地存储，无需额外基础设施）。

```bash
# Search via dashboard (port 8960) or API
curl localhost:8960/api/search?q=project+deadline&mode=hybrid
```

## 隐私保护措施

- 所有数据均存储在 SQLite 和 LanceDB 中
- 数据会自动根据配置的保留期限进行清理
- 不会存储音频内容，仅保存对话记录
- 可通过“仪表板 → 设置 → 隐私”选项进行详细隐私设置

## 实时监控界面

您可以通过 `http://localhost:8960` 查看实时监控界面：
- 实时对话流
- 实体关系可视化展示
- 在所有对话中搜索信息
- 分析报告和使用统计数据

## 链接

- **GitHub仓库：** https://github.com/GetPercept/percept