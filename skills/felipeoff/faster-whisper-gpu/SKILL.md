---
name: faster-whisper-gpu
description: ä½¿ç”¨Faster WhisperæŠ€æœ¯ç»“åˆNVIDIA GPUåŠ é€Ÿï¼Œå®ç°é«˜æ€§èƒ½çš„æœ¬åœ°è¯­éŸ³è½¬æ–‡æœ¬åŠŸèƒ½ã€‚æ— éœ€å°†éŸ³é¢‘æ–‡ä»¶å‘é€åˆ°å¤–éƒ¨æœåŠ¡ï¼Œå³å¯å®Œæˆæœ¬åœ°è½¬å½•ã€‚
homepage: https://github.com/FelipeOFF/faster-whisper-gpu
metadata:
  clawdbot:
    emoji: ğŸ™ï¸
    category: audio
    tags:
      - transcription
      - stt
      - speech-to-text
      - whisper
      - gpu
      - cuda
      - local
      - privacy
    requires:
      bins:
        - python3
      python_packages:
        - faster-whisper
        - torch
    install:
      - id: pip
        kind: pip
        packages:
          - faster-whisper
          - torch
        label: Install faster-whisper and PyTorch
---
# ğŸ™ï¸ æ›´å¿«çš„ Whisper GPU ç‰ˆæœ¬

ä½¿ç”¨ [Faster Whisper](https://github.com/SYSTRAN/faster-whisper) ç»“åˆ NVIDIA GPU åŠ é€ŸæŠ€æœ¯ï¼Œå®ç°é«˜æ€§èƒ½çš„æœ¬åœ°è¯­éŸ³è½¬æ–‡æœ¬åŠŸèƒ½ã€‚

## âœ¨ ä¸»è¦ç‰¹æ€§

- **ğŸš€ GPU åŠ é€Ÿ**ï¼šåˆ©ç”¨ NVIDIA CUDA å®ç°è¶…å¿«é€Ÿçš„è¯­éŸ³è½¬æ–‡æœ¬å¤„ç†
- **ğŸ”’ 100% æœ¬åœ°å¤„ç†**ï¼šæ‰€æœ‰æ•°æ®å‡ä¿ç•™åœ¨æ‚¨çš„è®¾å¤‡ä¸Šï¼Œå®Œå…¨ä¿æŠ¤éšç§
- **ğŸ’° æ°¸ä¹…å…è´¹**ï¼šæ— éœ€æ”¯ä»˜ API è´¹ç”¨ï¼Œå¯æ— é™æ¬¡è¿›è¡Œè¯­éŸ³è½¬æ–‡æœ¬æ“ä½œ
- **ğŸŒ å¤šè¯­è¨€æ”¯æŒ**ï¼šæ”¯æŒ 99 ç§è¯­è¨€ï¼Œå¹¶èƒ½è‡ªåŠ¨è¯†åˆ«è¯­è¨€
- **ğŸ“ å¤šç§è¾“å‡ºæ ¼å¼**ï¼šè¾“å…¥æ ¼å¼åŒ…æ‹¬ MP3ã€WAVã€FLACã€OGGã€M4Aï¼›è¾“å‡ºæ ¼å¼åŒ…æ‹¬ TXTã€SRTã€JSON
- **ğŸ¯ å¤šç§æ¨¡å‹é€‰æ‹©**ï¼šæä¾›å¤šç§æ¨¡å‹ï¼Œä»å°å‹æ¨¡å‹ï¼ˆé€Ÿåº¦å¿«ï¼‰åˆ°å¤§å‹æ¨¡å‹ï¼ˆå‡†ç¡®åº¦é«˜ï¼‰
- **ğŸ¬ å­—å¹•ç”Ÿæˆ**ï¼šæ”¯æŒç”ŸæˆåŒ…å«å•è¯æ—¶é—´æˆ³çš„ SRT æ ¼å¼å­—å¹•

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶
- æ”¯æŒ CUDA çš„ NVIDIA GPUï¼ˆæ¨èé…ç½®ï¼š4GB ä»¥ä¸Šæ˜¾å­˜ï¼‰
- æˆ–ä»…ä½¿ç”¨ CPUï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼Œä½†é€‚ç”¨äºæ‰€æœ‰è®¾å¤‡ï¼‰

### è½¯ä»¶
- Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
- NVIDIA é©±åŠ¨ç¨‹åº
- CUDA Toolkit 11.8 æˆ– 12.x ç‰ˆæœ¬

## ğŸš€ å¿«é€Ÿå…¥é—¨

### å®‰è£…

```bash
# Install dependencies
pip install faster-whisper torch

# Verify GPU is available
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

### åŸºæœ¬ç”¨æ³•

```bash
# Transcribe an audio file (auto-detects GPU)
python transcribe.py audio.mp3

# Specify language explicitly
python transcribe.py audio.mp3 --language pt

# Output as SRT subtitles
python transcribe.py audio.mp3 --format srt --output subtitles.srt

# Use larger model for better accuracy
python transcribe.py audio.mp3 --model large-v3
```

## ğŸ”§ é«˜çº§ç”¨æ³•

### å‘½ä»¤è¡Œå‚æ•°

```bash
python transcribe.py <audio_file> [options]

Options:
  --model {tiny,base,small,medium,large-v1,large-v2,large-v3}
                        Model size to use (default: base)
  --language LANG       Language code (e.g., 'pt', 'en', 'es'). Auto-detect if not specified.
  --format {txt,srt,json,vtt}
                        Output format (default: txt)
  --output FILE         Output file path (default: stdout)
  --device {cuda,cpu}   Device to use (default: cuda if available)
  --compute_type {int8,int8_float16,int16,float16,float32}
                        Computation precision (default: float16)
  --task {transcribe,translate}
                        Task: transcribe or translate to English (default: transcribe)
  --vad_filter          Enable voice activity detection filter
  --vad_parameters MIN_DURATION_ON,MIN_DURATION_OFF
                        VAD parameters as comma-separated values
  --condition_on_previous_text
                        Condition on previous text (default: True)
  --initial_prompt PROMPT
                        Initial prompt to guide transcription
  --word_timestamps     Include word-level timestamps (for SRT/JSON)
  --hotwords WORDS      Comma-separated hotwords to boost recognition
```

### ä½¿ç”¨ç¤ºä¾‹

#### è‘¡è„ç‰™è¯­è½¬æ–‡æœ¬ï¼ˆè¾“å‡ºä¸º SRT æ ¼å¼ï¼‰
```bash
python transcribe.py meeting.mp3 --language pt --format srt --output meeting.srt
```

#### ä»ä»»æ„è¯­è¨€ç¿»è¯‘æˆä¸­æ–‡
```bash
python transcribe.py japanese_audio.mp3 --task translate --format txt
```

#### ä½¿ç”¨é«˜ç²¾åº¦æ¨¡å‹è¿›è¡Œç¿»è¯‘
```bash
python transcribe.py podcast.mp3 --model large-v3 --vad_filter --word_timestamps
```

#### ä»…ä½¿ç”¨ CPUï¼ˆä¸ä½¿ç”¨ GPUï¼‰çš„æ¨¡å¼
```bash
python transcribe.py audio.mp3 --device cpu --compute_type int8
```

## ğŸ Python API

```python
from faster_whisper import WhisperModel

# Load model
model = WhisperModel("base", device="cuda", compute_type="float16")

# Transcribe
segments, info = model.transcribe("audio.mp3", language="pt")

print(f"Detected language: {info.language} (probability: {info.language_probability:.2f})")

for segment in segments:
    print(f"[{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}")
```

## ğŸ“Š æ¨¡å‹è§„æ ¼ä¸æ˜¾å­˜éœ€æ±‚

| æ¨¡å‹        | å‚æ•°            | æ‰€éœ€æ˜¾å­˜ï¼ˆMBï¼‰ | ç›¸å¯¹é€Ÿåº¦ | ç²¾ç¡®åº¦     |
|------------|----------------|-----------|---------|---------|
| tiny       | 39 MB           | çº¦ 1 GB      | çº¦ 32 å€    | åŸºç¡€çº§åˆ«   |
| base       | 74 MB           | çº¦ 1 GB      | çº¦ 16 å€    | è‰¯å¥½       |
| small      | 244 MB           | çº¦ 2 GB      | çº¦ 6 å€    | æ›´å¥½       |
| medium     | 769 MB           | çº¦ 5 GB      | çº¦ 2 å€    | éå¸¸å¥½    |
| large-v3     | 1550 MB          | çº¦ 10 GB     | 1 å€      | æœ€ä½³       |

*åŸºå‡†æµ‹è¯•åŸºäº NVIDIA RTX 4090 è¿›è¡Œ*

## ğŸ› ï¸ æ”¯æŒçš„è¯­è¨€

Faster Whisper æ”¯æŒ 99 ç§è¯­è¨€ï¼ŒåŒ…æ‹¬ï¼š
- **è‘¡è„ç‰™è¯­** (`pt`)
- **è‹±è¯­** (`en`)
- **è¥¿ç­ç‰™è¯­** (`es`)
- **æ³•è¯­** (`fr`)
- **å¾·è¯­** (`de`)
- **æ„å¤§åˆ©è¯­** (`it`)
- **æ—¥è¯­** (`ja`)
- **ä¸­æ–‡** (`zh`)
- **ä¿„è¯­** (`ru`)
- **ä»¥åŠæ›´å¤šè¯­è¨€...**

## ğŸ› ï¸ æ•…éšœæ’é™¤

### CUDA å†…å­˜ä¸è¶³é—®é¢˜
```bash
# Use smaller model
python transcribe.py audio.mp3 --model tiny

# Or use CPU
python transcribe.py audio.mp3 --device cpu

# Or reduce precision
python transcribe.py audio.mp3 --compute_type int8
```

### æ¨¡å‹ä¸‹è½½é—®é¢˜
é¦–æ¬¡ä½¿ç”¨æ—¶ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½åˆ° `~/.cache/huggingface/hub/` ç›®å½•ä¸­ã€‚
å¦‚æœä½¿ç”¨ä»£ç†æœåŠ¡å™¨ï¼Œè¯·è®¾ç½®ç›¸å…³é…ç½®ï¼š
```bash
export HF_HOME=/path/to/custom/cache
```

### è½¬æ–‡æœ¬é€Ÿåº¦è¾ƒæ…¢çš„é—®é¢˜
- ç¡®ä¿ GPU è¢«æ­£ç¡®ä½¿ç”¨ï¼ˆåœ¨è½¬æ–‡æœ¬è¿‡ç¨‹ä¸­æŸ¥çœ‹ `nvidia-smi` è¾“å‡ºï¼‰
- é€‰æ‹©è¾ƒå°çš„æ¨¡å‹ä»¥è·å¾—æ›´å¿«ç»“æœ
- å¯ç”¨ VADï¼ˆVoice Activity Detectionï¼‰è¿‡æ»¤å™¨ä»¥è·³è¿‡é™éŸ³éƒ¨åˆ†

## ğŸ¤ è´¡çŒ®æ–¹å¼

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š
1. å…‹éš†é¡¹ç›®ä»“åº“
2. åˆ›å»ºä¸€ä¸ªæ–°çš„åŠŸèƒ½åˆ†æ”¯
3. æäº¤æ‹‰å–è¯·æ±‚ï¼ˆpull requestï¼‰

## ğŸ“œ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ï¼Œè¯¦ç»†ä¿¡æ¯è¯·å‚é˜… [LICENSE](LICENSE) æ–‡ä»¶ã€‚

Faster Whisper ç”± [SYSTRAN](https://github.com/SYSTRAN/faster-whisper) å¼€å‘ï¼ŒåŸºäº OpenAI çš„ Whisper æ¨¡å‹è¿›è¡Œä¼˜åŒ–ã€‚

## ğŸ™ è‡´è°¢

- [OpenAI Whisper](https://github.com/openai/whisper)ï¼šåŸå§‹æ¨¡å‹
- [Faster Whisper](https://github.com/SYSTRAN/faster-whisper)ï¼šä¼˜åŒ–åçš„å®ç°
- [CTranslate2](https://github.com/OpenNMT/CTranslate2)ï¼šå¿«é€Ÿæ¨ç†å¼•æ“

---

**ä¸“ä¸º OpenClaw ç¤¾åŒºç²¾å¿ƒåˆ¶ä½œ â¤ï¸**