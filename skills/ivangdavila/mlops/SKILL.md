---
name: MLOps
slug: mlops
version: 1.0.0
description: "使用管道（pipelines）、监控（monitoring）、服务（serving）以及可复现性（reproducibility）的最佳实践，将机器学习（ML）模型部署到生产环境中。"
metadata: {"clawdbot":{"emoji":"🤖","requires":{"bins":[]},"os":["linux","darwin","win32"]}}
---
## 快速参考

| 主题 | 文件 | 常见陷阱 |
|-------|------|----------|
| 持续集成/持续部署（CI/CD）与有向无环图（DAGs） | `pipelines.md` | 训练过程与推理过程之间的依赖关系耦合 |
| 模型部署与服务 | `serving.md` | 大型模型启动时可能出现延迟（冷启动问题） |
| 模型漂移与警报 | `monitoring.md` | 仅关注技术指标，忽略其他关键因素 |
| 版本控制 | `reproducibility.md` | 预处理步骤未进行版本控制，导致结果不可复现 |
| GPU基础设施 | `gpu.md` | 提交GPU请求时，会占用整个GPU设备 |

## 重要陷阱

**训练与部署之间的差异：**
- 笔记本中的预处理步骤与实际部署环境中的预处理步骤可能不同，这可能导致隐藏的错误（无声的bug）。
- 笔记本中使用Pandas库可能导致生产环境中的内存泄漏（应使用原生的数据类型）。
- 训练时使用的特征值与部署时使用的特征值可能不一致，除非进行了正确的连接操作。

**GPU内存管理：**
- `requests.nvidia.com/gpu: 1` 的请求会占用整个GPU，而不仅仅是部分内存。
- 多GPU卡（MIG/MPS）之间的资源共享存在实际限制，无法实现即插即用。
- 当GPU内存不足（OOM）时，系统会终止相关进程，且不会留下有用的日志。

**模型版本控制与代码版本控制的区别：**
- 模型的相关文件（如模型结构、训练配置等）需要单独进行版本控制（使用MLflow、W&B、DVC等工具）。
- 可复现性要求包括训练数据版本、预处理步骤版本以及代码版本的统一管理。
- 回滚操作需要确保旧模型版本仍然可以正常部署。

**漂移检测时机：**
- 触发模型重新训练的条件不应仅仅是“漂移量超过阈值”，还需考虑成本与效益的平衡。
- 如果延迟获取真实数据，可能会导致漂移检测结果出现数周的延迟。
- 上游数据管道的变更也可能导致模型漂移，但此时模型本身可能并未出现问题。

## 范围

本文档仅涵盖以下内容：
- 模型的持续集成/持续部署流程（CI/CD）
- 模型的部署与服务机制
- 模型监控与漂移检测方法
- 可复现性实践
- GPU基础设施的优化方案

**不涵盖的内容：**
- 机器学习算法
- 特征工程
- 超参数调优