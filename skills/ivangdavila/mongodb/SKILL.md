---
name: MongoDB
slug: mongodb
version: 1.0.1
description: 设计 MongoDB 数据库模式时，需要考虑正确的嵌入（embedding）方式、索引（indexing）策略、聚合（aggregation）功能以及适用于生产环境的最佳实践（production-ready patterns）。
metadata: {"clawdbot":{"emoji":"🍃","requires":{"anyBins":["mongosh","mongo"]},"os":["linux","darwin","win32"]}}
---

## 适用场景

当用户需要具备 MongoDB 的专业知识时，无论是从数据库架构设计到生产环境中的性能优化，都可以使用该工具。该工具能够处理文档建模、索引策略、聚合管道、数据一致性以及系统扩展等方面的问题。

## 快速参考

| 主题 | 对应文件 |
|-------|------|
| 数据库架构设计模式 | `schema.md` |
| 索引策略 | `indexes.md` |
| 聚合管道 | `aggregation.md` |
| 生产环境配置 | `production.md` |

## 数据库架构设计原则

- 当数据需要被一起查询且不会无限增长时，建议使用嵌入式数据结构（Embedded Data）。
- 当数据量较大、被独立访问或存在多对多关系时，应使用引用（Reference）方式。
- 为提升读取性能，可以考虑对数据进行反规范化（Denormalize）；不过这会增加数据更新的复杂性（因为没有 JOIN 操作会导致数据重复）。
- 设计数据库架构时应以实际查询需求为导向，而非追求数据结构的规范化。

## 需要注意的数据大小问题

- 单个文档的最大大小限制为 16MB，请从一开始就做好规划；对于大型文件，可以使用 GridFS 来存储。
- 如果数组的大小会无限增长，可能会导致严重问题，应采用分桶（Bucketing）策略来管理数据。
- BSON 格式会带来一定的开销（每个字段名在文档中都会被重复存储），使用简短的字段名可以在大规模数据存储时节省空间。
- 数组的嵌套深度最多为 100 层；虽然这种情况很少发生，但仍然需要注意。

## 数组使用中的常见问题

- 数组中的元素数量超过 1000 个时，性能会受到影响；此时在文档内部进行分页操作会变得非常困难。
- 使用 `$push` 方法时如果没有配合 `$slice` 限制，数组的大小可能会无限增长，应使用 `$push: {$each: [...], $slice: -100}` 来控制数组长度。
- 对数组字段创建多键索引（Multikey Index）时，每个元素都会占用索引空间，这可能导致索引文件变得非常庞大。
- 在复合索引中，不能对多个数组字段同时创建多键索引。

## `$lookup` 操作中的注意事项

- 随着集合规模的增加，`$lookup` 操作的性能会下降；在 MongoDB 5.0 之前，外层集合如果没有索引的话，`$lookup` 会效率低下。
- 每个聚合管道阶段只能使用一次 `$lookup` 操作；嵌套的 `$lookup` 会导致查询复杂度增加和性能下降。
- 从 MongoDB 5.0 开始，`$lookup` 操作可以在连接数据之前进行过滤，从而显著提升性能。如果频繁使用 `$lookup`，可以考虑使用嵌入式数据结构代替。

## 索引策略

- 索引创建的优先级规则：首先创建用于比较操作（如 `$eq`）的索引，然后是排序操作（如 `$sort`），最后是范围查询（如 `$range`）的索引。
- MongoDB 不支持高效的索引交集操作；通常情况下，使用单个复合索引效果更好。
- 每个集合只能创建一个文本索引；对于复杂的文本查询，可以考虑使用 Atlas Search 功能。
- 可以使用 TTL 索引来实现数据的自动过期：`{createdAt: 1}, {expireAfterSeconds: 86400}`。

## 数据一致性相关的问题

- 默认的读写策略（`{w: "majority", readConcern: "majority"}`）并不能保证数据完全一致；对于需要强一致性的场景，应使用更严格的策略。
- 自 MongoDB 4.0 开始支持多文档事务，但事务会增加延迟和锁的开销，因此应尽量减少事务的使用。
- 单个文档的操作是原子的（Atomic），可以利用这一点将相关数据嵌入到文档中以提高数据一致性。
- 在连接字符串中设置 `retryWrites: true` 可以自动处理临时性的连接故障。

## 读取操作中的注意事项

- 从从节点读取数据时可能会遇到数据过时的问题（Stale Data），因为复制延迟可能会导致数据延迟几秒。
- 使用 `nearest` 策略可以获得最低的读取延迟，但可能会读取到过时的数据。
- 写操作总是写入主节点；读取策略不会影响写操作的结果。
- 如果需要确保数据的一致性，可以使用 `primary` 节点或基于会话的因果一致性（Session-Based Causal Consistency）机制。

## ObjectId 的相关问题

- ObjectId 包含创建时间戳（`ObjectId.getTimestamp()` 可以获取创建时间），无需额外字段即可获取创建时间。
- ObjectId 是大致按时间顺序排列的，可以通过 `_id` 字段对数据进行排序。
- ObjectId 并不是随机生成的；如果知道数据的创建时间，可以预测其顺序，但不要依赖这一点来确保数据安全性。

## 性能优化方面的建议

- 使用 `explain("executionStats")` 可以查看实际的执行情况，而不仅仅是查询计划。
- `totalDocsExamined` 与 `nReturned` 的比值应该接近 1，否则说明索引可能存在问题。
- 如果查询使用了 `COLLSCAN`，说明数据库进行了全集合扫描；需要为相关字段创建合适的索引。
- 如果查询使用了 `IXSCAN` 且 `totalDocsExamined` 的值为 0，说明所有数据都是从索引中获取的。

## 数据聚合的相关原则

- 聚合管道中的各个阶段都是对数据的转换操作；应尽量提前进行数据过滤（`$match`）和投影（`$project`）操作，以减少数据量。
- 在 `unwind` 操作之前使用 `$match` 可以利用索引加速查询；在 `unwind` 之后使用 `$match` 则无法利用索引。
- 应逐步测试复杂的聚合管道，逐步优化代码。

## 常见错误

- 认为 MongoDB 是“无模式”的数据库（Schemaless）：实际上仍然需要数据库架构设计，只是这种设计在应用程序层面实现，而不是在数据库层面强制执行。
- 不创建索引会导致数据库对整个集合进行全扫描；每种查询方式都需要相应的索引。
- 使用数组来存储大量数据可能会导致文档大小超过 16MB 的限制，或者影响 BSON 数据的解析速度。
- 忽视写操作的原子性可能会导致数据虽然被写入但未被持久化或复制到其他节点。