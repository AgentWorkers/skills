---
summary: "Ollama Model Tuner: Locally fine-tune prompts, LoRAs, and models with Ollama for custom tasks."
description: "Optimize Ollama models/prompts using local datasets, eval metrics, and iterative tuning. No cloud needed."
triggers:
  - "tune ollama"
  - "optimize ollama model"
  - "fine-tune local LLM"
  - "ollama prompt engineer"
read_when:
  - "ollama tune" in message
  - "model fine-tune" in message
---

# Ollama æ¨¡å‹è°ƒä¼˜å™¨ v1.0.0

## ğŸ¯ ä¸»è¦åŠŸèƒ½
- æä¾›æç¤ºå·¥ç¨‹ï¼ˆprompt engineeringï¼‰å’Œ A/B æµ‹è¯•åŠŸèƒ½
- å…è®¸ç”¨æˆ·è‡ªå®šä¹‰æ¨¡å‹æ–‡ä»¶ï¼ˆmodelfile customizationï¼‰
- ä½¿ç”¨æœ¬åœ°æ•°æ®è¿›è¡Œ LoRAï¼ˆLow-Rank Autoencoderï¼‰å¾®è°ƒ
- æ”¯æŒæ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ˆperformance benchmarkingï¼‰

## ğŸš€ å¿«é€Ÿå…¥é—¨
```
!ollama-model-tuner --model llama3 --dataset ./data.json --task classification
```

## ç›¸å…³æ–‡ä»¶
- `scripts/tune.py`ï¼šåŸºäº Python çš„è°ƒä¼˜å·¥å…·ï¼ŒåŒ…å«è¯„ä¼°å¾ªç¯ï¼ˆeval loopï¼‰
- `prompts/system.md`ï¼šåŸºç¡€ç³»ç»Ÿæç¤ºï¼ˆsystem promptsï¼‰æ–‡ä»¶

## æ”¯æŒçš„ç¯å¢ƒä¸æ ¼å¼
- Ollama ç‰ˆæœ¬ï¼š0.3 åŠä»¥ä¸Š
- Python ç‰ˆæœ¬ï¼š3.10 åŠä»¥ä¸Š
- æ•°æ®é›†æ ¼å¼ï¼šJSONL æˆ– CSV

ï¼ˆæ³¨ï¼šç”±äºæ–‡ä»¶å†…å®¹ä¸»è¦ä¸ºä»£ç å’Œé…ç½®ä¿¡æ¯ï¼Œç¿»è¯‘æ—¶æœªæ·»åŠ è¿‡å¤šçš„è§£é‡Šæ€§æ–‡å­—ã€‚è‹¥éœ€è¦è¿›ä¸€æ­¥è¯´æ˜æŸäº›æŠ€æœ¯ç»†èŠ‚æˆ–åŠŸèƒ½ï¼Œå¯åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œè¡¥å……ã€‚ï¼‰