---
name: emergency-rescue
description: **ä»å¼€å‘äººå‘˜å¼•å‘çš„ç¾éš¾ä¸­æ¢å¤**  
å½“é‡åˆ°ä»¥ä¸‹æƒ…å†µæ—¶ï¼Œè¯·ä½¿ç”¨æ­¤æ–¹æ¡ˆï¼š  
- æœ‰äººå°†ä»£ç å¼ºåˆ¶æ¨é€åˆ°ä¸»åˆ†æ”¯ï¼ˆmain branchï¼‰ï¼›  
- Git ä¸­çš„å‡­æ®è¢«æ³„éœ²ï¼›  
- ç£ç›˜ç©ºé—´è€—å°½ï¼›  
- é”™è¯¯åœ°ç»ˆæ­¢äº†æŸä¸ªè¿›ç¨‹ï¼›  
- æ•°æ®åº“è¢«æŸåï¼›  
- éƒ¨ç½²å¤±è´¥ï¼›  
- ç”¨æˆ·å› æ“ä½œå¤±è¯¯è€Œæ— æ³•é€šè¿‡ SSH è¿›å…¥ç³»ç»Ÿï¼›  
- åœ¨æ‰§è¡Œé”™è¯¯çš„ `rebase` æ“ä½œåä¸¢å¤±äº†æäº¤è®°å½•ï¼›  
- æˆ–è€…é‡åˆ°ä»»ä½•å…¶ä»–éœ€è¦ç«‹å³ã€å†·é™ä¸”æŒ‰æ­¥éª¤å¤„ç†çš„ç´§æ€¥æƒ…å†µã€‚  

**ä½¿ç”¨æ­¥éª¤ï¼š**  
1. ä¿æŒå†·é™ï¼Œåˆ†æé—®é¢˜çš„æ ¹æœ¬åŸå› ã€‚  
2. æ ¹æ®å…·ä½“æƒ…å†µï¼Œé‡‡å–ç›¸åº”çš„æ¢å¤æªæ–½ï¼ˆä¾‹å¦‚ï¼šé‡æ–°é…ç½® Git ä»“åº“ã€æ¢å¤æ•°æ®åº“æ•°æ®ã€é‡æ–°å¯åŠ¨ç›¸å…³æœåŠ¡ã€ä¿®å¤ç³»ç»Ÿé”™è¯¯ç­‰ï¼‰ã€‚  
3. å¦‚æœéœ€è¦ï¼Œè®°å½•æ•´ä¸ªæ¢å¤è¿‡ç¨‹ï¼Œä»¥ä¾¿å°†æ¥å‚è€ƒã€‚  

**æ³¨æ„ï¼š**  
- è¯·ç¡®ä¿åœ¨æ¢å¤è¿‡ç¨‹ä¸­éµå¾ªæœ€ä½³å®è·µå’Œå›¢é˜Ÿè§„èŒƒï¼Œä»¥é¿å…ç±»ä¼¼é—®é¢˜çš„å†æ¬¡å‘ç”Ÿã€‚  
- å¦‚æœ‰ç–‘é—®ï¼Œè¯·åŠæ—¶å‘å›¢é˜Ÿæˆå‘˜æˆ–æŠ€æœ¯æ”¯æŒäººå‘˜å¯»æ±‚å¸®åŠ©ã€‚
metadata: {"clawdbot":{"emoji":"ğŸš¨","requires":{"anyBins":["git","bash"]},"os":["linux","darwin","win32"]}}
---

# ç´§æ€¥æ•‘æ´å·¥å…·åŒ…

æœ¬å·¥å…·åŒ…æä¾›äº†é’ˆå¯¹å¼€å‘è€…å·¥ä½œä¸­å¯èƒ½é‡åˆ°çš„å„ç§ç´§æ€¥æƒ…å†µçš„é€æ­¥æ¢å¤æµç¨‹ã€‚æ‰€æœ‰æµç¨‹éƒ½éµå¾ªç›¸åŒçš„æ­¥éª¤ï¼š**è¯Šæ–­ â†’ ä¿®å¤ â†’ éªŒè¯**ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œæ‰§è¡Œçš„å‘½ä»¤éƒ½æ˜¯éç ´åæ€§çš„ï¼›å…·æœ‰ç ´åæ€§çš„æ“ä½œä¼šç‰¹åˆ«æ ‡æ˜ã€‚

å½“å‡ºç°é—®é¢˜æ—¶ï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µé€‰æ‹©ç›¸åº”çš„æµç¨‹å¹¶æŒ‰é¡ºåºæ‰§è¡Œæ“ä½œã€‚

## ä½¿ç”¨åœºæ™¯

- æœ‰äººå¼ºåˆ¶æ¨é€ä»£ç åˆ°ä¸»åˆ†æ”¯ï¼ˆmainï¼‰å¹¶è¦†ç›–äº†å†å²è®°å½•
- å‡­æ®è¢«æäº¤åˆ°äº†å…¬å…±ä»“åº“
- ä½¿ç”¨ `git rebase` æˆ– `git reset --hard` æ“ä½œå¯¼è‡´æŸäº›æäº¤ä¸¢å¤±
- ç£ç›˜ç©ºé—´å·²æ»¡ï¼Œå¯¼è‡´ç³»ç»Ÿæ— æ³•æ­£å¸¸è¿è¡Œ
- æŸä¸ªè¿›ç¨‹å ç”¨è¿‡å¤šå†…å­˜æˆ–æ— æ³•ç»ˆæ­¢
- æ•°æ®åº“è¿ç§»ä¸­é€”å¤±è´¥
- éœ€è¦ç«‹å³å›æ»šéƒ¨ç½²
- SSH è®¿é—®è¢«é”å®š
- ç”Ÿäº§ç¯å¢ƒä¸­çš„ SSL è¯ä¹¦å·²è¿‡æœŸ
- æ— æ³•ç¡®å®šé—®é¢˜æ‰€åœ¨ï¼Œä½†ç³»ç»Ÿæ˜æ˜¾å‡ºç°æ•…éšœ

---

## Git ç›¸å…³ç´§æ€¥æƒ…å†µ

### å¼ºåˆ¶æ¨é€ä»£ç åˆ°ä¸»åˆ†æ”¯ï¼ˆæˆ–ä»»ä½•å…±äº«åˆ†æ”¯ï¼‰

æœ‰äººæ‰§è¡Œäº† `git push --force`ï¼Œå¯¼è‡´è¿œç¨‹ä»“åº“çš„å†å²è®°å½•è¢«è¦†ç›–ã€‚

```bash
# DIAGNOSE: Check the reflog on any machine that had the old state
git reflog show origin/main
# Look for the last known-good commit hash

# FIX (if you have the old state locally):
git push origin <good-commit-hash>:main --force-with-lease
# --force-with-lease is safer than --force: it fails if remote changed again

# FIX (if you DON'T have the old state locally):
# GitHub/GitLab retain force-pushed refs temporarily

# GitHub: check the "push" event in the audit log or use the API
gh api repos/{owner}/{repo}/events --jq '.[] | select(.type=="PushEvent") | .payload.before'

# GitLab: check the reflog on the server (admin access needed)
# Or restore from any CI runner or team member's local clone

# VERIFY:
git log --oneline -10 origin/main
# Confirm the history looks correct
```

### ä½¿ç”¨ `git rebase` æˆ– `git reset --hard` åæäº¤ä¸¢å¤±

æ‰§è¡Œ `git rebase` æˆ– `git reset --hard` åï¼Œéƒ¨åˆ†æäº¤è¢«åˆ é™¤ã€‚

```bash
# DIAGNOSE: Your commits are NOT gone. Git keeps everything for 30+ days.
git reflog
# Find the commit hash from BEFORE the rebase/reset
# Look for entries like "rebase (start)" or "reset: moving to"

# FIX: Reset back to the pre-disaster state
git reset --hard <commit-hash-before-disaster>

# FIX (alternative): Cherry-pick specific lost commits
git cherry-pick <lost-commit-hash>

# FIX (if reflog is empty â€” rare, usually means different repo):
git fsck --lost-found
# Look in .git/lost-found/commit/ for dangling commits
ls .git/lost-found/commit/
git show <hash>  # Inspect each one

# VERIFY:
git log --oneline -10
# Your commits should be back
```

### æäº¤åˆ°äº†é”™è¯¯çš„åˆ†æ”¯

åœ¨ä¸»åˆ†æ”¯ï¼ˆmainï¼‰ä¸Šè¿›è¡Œäº†æœ¬åº”æäº¤åˆ°åŠŸèƒ½åˆ†æ”¯ï¼ˆfeature branchï¼‰çš„ä¿®æ”¹ã€‚

```bash
# DIAGNOSE: Check where you are and what you committed
git log --oneline -5
git branch

# FIX: Create the feature branch at current position, then reset main
git branch feature-branch          # Create branch pointing at current commit
git reset --hard HEAD~<N>          # Move main back N commits (âš ï¸ destructive)
git checkout feature-branch        # Switch to the new branch

# FIX (safer alternative using cherry-pick):
git checkout -b feature-branch     # Create and switch to new branch
git checkout main
git reset --hard origin/main       # Reset main to remote state
# Your commits are safely on feature-branch

# VERIFY:
git log --oneline main -5
git log --oneline feature-branch -5
```

### åˆå¹¶æ“ä½œå¤±è´¥ï¼ˆå‡ºç°å†²çªï¼Œç»“æœé”™è¯¯ï¼‰

åˆå¹¶æ“ä½œå¯¼è‡´é”™è¯¯ç»“æœï¼Œéœ€è¦é‡æ–°å¼€å§‹ã€‚

```bash
# FIX (merge not yet committed â€” still in conflict state):
git merge --abort

# FIX (merge was committed but not pushed):
git reset --hard HEAD~1

# FIX (merge was already pushed): Create a revert commit
git revert -m 1 <merge-commit-hash>
# -m 1 means "keep the first parent" (your branch before merge)
git push

# VERIFY:
git log --oneline --graph -10
git diff HEAD~1  # Review what changed
```

### Git ä»“åº“æŸå

Git å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œæç¤ºâ€œå¯¹è±¡æŸåâ€ï¼ˆbad objectï¼‰æˆ–â€œé“¾æ¥å¤±æ•ˆâ€ï¼ˆbroken linkï¼‰ç­‰é”™è¯¯ã€‚

```bash
# DIAGNOSE: Check repository integrity
git fsck --full

# FIX (if remote is intact â€” most common):
# Save any uncommitted work first
cp -r . ../repo-backup

# Re-clone and restore local work
cd ..
git clone <remote-url> repo-fresh
cp -r repo-backup/path/to/uncommitted/files repo-fresh/

# FIX (repair without re-cloning):
# Remove corrupt objects and fetch them again
git fsck --full 2>&1 | grep "corrupt\|missing" | awk '{print $NF}'
# For each corrupt object:
rm .git/objects/<first-2-chars>/<remaining-hash>
git fetch origin  # Re-download from remote

# VERIFY:
git fsck --full  # Should report no errors
git log --oneline -5
```

---

## å‡­æ®æ³„éœ²

### é‡è¦ä¿¡æ¯è¢«æäº¤åˆ°äº† Git ä»“åº“ï¼ˆAPI å¯†é’¥ã€å¯†ç ã€è®¿é—®ä»¤ç‰Œï¼‰

æ•æ„Ÿä¿¡æ¯è¢«è®°å½•åœ¨ Git å†å²è®°å½•ä¸­ã€‚æ—¶é—´éå¸¸ç´§è¿«â€”â€”è‡ªåŠ¨åŒ–ç›‘æ§å·¥å…·ä¼šå®æ—¶æ‰«æå…¬å…± GitHub ä»“åº“ä»¥æ£€æµ‹æ³„éœ²çš„å‡­è¯ã€‚

```bash
# STEP 1: REVOKE THE CREDENTIAL IMMEDIATELY
# Do this FIRST, before cleaning git history.
# The credential is already compromised the moment it was pushed publicly.

# AWS keys:
aws iam delete-access-key --access-key-id AKIAXXXXXXXXXXXXXXXX --user-name <user>
# Then create a new key pair

# GitHub tokens:
# Go to github.com â†’ Settings â†’ Developer settings â†’ Tokens â†’ Revoke

# Database passwords:
# Change the password in the database immediately
# ALTER USER myuser WITH PASSWORD 'new-secure-password';

# Generic API tokens:
# Revoke in the provider's dashboard, generate new ones

# STEP 2: Remove from current branch
git rm --cached <file-with-secret>    # If the whole file is secret
# OR edit the file to remove the secret, then:
git add <file>

# STEP 3: Add to .gitignore
echo ".env" >> .gitignore
echo "credentials.json" >> .gitignore
git add .gitignore

# STEP 4: Remove from git history (âš ï¸ rewrites history)
# Option A: git-filter-repo (recommended, install with pip install git-filter-repo)
git filter-repo --path <file-with-secret> --invert-paths

# Option B: BFG Repo Cleaner (faster for large repos)
# Download from https://rtyley.github.io/bfg-repo-cleaner/
java -jar bfg.jar --delete-files <filename> .
git reflog expire --expire=now --all
git gc --prune=now --aggressive

# STEP 5: Force push the cleaned history
git push origin --force --all
git push origin --force --tags

# STEP 6: Notify all collaborators to re-clone
# Their local copies still have the secret in reflog

# VERIFY:
git log --all -p -S '<the-secret-string>' --diff-filter=A
# Should return nothing
```

### `.env` æ–‡ä»¶è¢«æäº¤åˆ°äº†å…¬å…±ä»“åº“

é…ç½®æ–‡ä»¶ `.env` è¢«æ„å¤–æäº¤åˆ°äº†å…¬å…±ä»“åº“ã€‚

```bash
# STEP 1: Revoke ALL credentials in that .env file. All of them. Now.

# STEP 2: Remove and ignore
git rm --cached .env
echo ".env" >> .gitignore
git add .gitignore
git commit -m "Remove .env from tracking"

# STEP 3: Remove from history (see credential removal above)
git filter-repo --path .env --invert-paths

# STEP 4: Check what was exposed
# List every variable that was in the .env:
git show HEAD~1:.env 2>/dev/null || git log --all -p -- .env | head -50
# Rotate every single value.

# PREVENTION: Add a pre-commit hook
cat > .git/hooks/pre-commit << 'HOOK'
#!/bin/bash
if git diff --cached --name-only | grep -qE '\.env$|\.env\.local$|credentials'; then
    echo "ERROR: Attempting to commit potential secrets file"
    echo "Files: $(git diff --cached --name-only | grep -E '\.env|credentials')"
    exit 1
fi
HOOK
chmod +x .git/hooks/pre-commit
```

### æœºå¯†ä¿¡æ¯å‡ºç°åœ¨æŒç»­é›†æˆ/æŒç»­éƒ¨ç½²ï¼ˆCI/CDï¼‰æ—¥å¿—ä¸­

æœºå¯†ä¿¡æ¯è¢«è®°å½•åœ¨ CI/CD æ—¥å¿—ä¸­ã€‚

```bash
# STEP 1: Revoke the credential immediately

# STEP 2: Delete the CI run/logs if possible
# GitHub Actions:
gh run delete <run-id>
# Or: Settings â†’ Actions â†’ delete specific run

# STEP 3: Fix the pipeline
# Never echo secrets. Mask them:
# GitHub Actions: echo "::add-mask::$MY_SECRET"
# GitLab CI: variables are masked if marked as "Masked" in settings

# STEP 4: Audit what was exposed
# Check the log output for patterns like:
# AKIAXXXXXXXXX (AWS)
# ghp_XXXXXXXXX (GitHub)
# sk-XXXXXXXXXXX (OpenAI/Stripe)
# Any connection strings with passwords
```

## ç£ç›˜ç©ºé—´ä¸è¶³çš„ç´§æ€¥æƒ…å†µ

### ç³»ç»Ÿæˆ–å®¹å™¨ç£ç›˜ç©ºé—´å·²æ»¡

ç³»ç»Ÿæ— æ³•æ­£å¸¸è¿è¡Œï¼šæ„å»ºä»»åŠ¡å¤±è´¥ï¼Œæ—¥å¿—æ— æ³•è®°å½•ï¼ŒæœåŠ¡å´©æºƒã€‚

```bash
# DIAGNOSE: What's using space?
df -h                          # Which filesystem is full?
du -sh /* 2>/dev/null | sort -rh | head -20    # Biggest top-level dirs
du -sh /var/log/* | sort -rh | head -10        # Log bloat?

# QUICK WINS (safe to run immediately):

# 1. Docker cleanup (often the #1 cause)
docker system df               # See Docker disk usage
docker system prune -a -f      # Remove all unused images, containers, networks
docker volume prune -f          # Remove unused volumes
docker builder prune -a -f      # Remove build cache
# âš ï¸ This removes ALL unused Docker data. Safe if you can re-pull/rebuild.

# 2. Package manager caches
# npm
npm cache clean --force
rm -rf ~/.npm/_cacache

# pip
pip cache purge

# apt
sudo apt-get clean
sudo apt-get autoremove -y

# brew
brew cleanup --prune=all

# 3. Log rotation (immediate)
# Truncate (not delete) large log files to free space instantly
sudo truncate -s 0 /var/log/syslog
sudo truncate -s 0 /var/log/journal/*/*.journal  # systemd journals
find /var/log -name "*.log" -size +100M -exec truncate -s 0 {} \;
# Truncate preserves the file handle so services don't break

# 4. Old build artifacts
find . -name "node_modules" -type d -prune -exec rm -rf {} + 2>/dev/null
find . -name ".next" -type d -exec rm -rf {} + 2>/dev/null
find . -name "dist" -type d -exec rm -rf {} + 2>/dev/null
find /tmp -type f -mtime +7 -delete 2>/dev/null

# 5. Find the actual culprit
find / -xdev -type f -size +100M -exec ls -lh {} \; 2>/dev/null | sort -k5 -rh | head -20
# Shows files over 100MB, sorted by size

# VERIFY:
df -h  # Check free space increased
```

### Docker å®¹å™¨ç£ç›˜ç©ºé—´ä¸è¶³

Docker å®¹å™¨å†…çš„ç£ç›˜ç©ºé—´å·²æ»¡ï¼Œå¯¼è‡´å®¹å™¨æ— æ³•å¯åŠ¨ã€‚

```bash
# DIAGNOSE:
docker system df -v

# Common culprits:
# 1. Dangling images from builds
docker image prune -f

# 2. Stopped containers accumulating
docker container prune -f

# 3. Build cache (often the biggest)
docker builder prune -a -f

# 4. Volumes from old containers
docker volume ls -qf dangling=true
docker volume prune -f

# NUCLEAR OPTION (âš ï¸ removes EVERYTHING):
docker system prune -a --volumes -f
# You will need to re-pull all images and recreate all volumes

# VERIFY:
docker system df
df -h
```

## è¿›ç¨‹ç›¸å…³ç´§æ€¥æƒ…å†µ

### ç«¯å£å·²è¢«å ç”¨

æŸä¸ªç«¯å£å·²è¢«å…¶ä»–è¿›ç¨‹å ç”¨ã€‚

```bash
# DIAGNOSE: What's using the port?
# Linux:
lsof -i :8080
ss -tlnp | grep 8080
# macOS:
lsof -i :8080
# Windows:
netstat -ano | findstr :8080

# FIX: Kill the process
kill $(lsof -t -i :8080)           # Graceful
kill -9 $(lsof -t -i :8080)       # Force (if graceful didn't work)

# FIX (Windows):
# Find PID from netstat output, then:
taskkill /PID <pid> /F

# FIX (if it's a leftover Docker container):
docker ps | grep 8080
docker stop <container-id>

# VERIFY:
lsof -i :8080  # Should return nothing
```

### è¿›ç¨‹æ— æ³•ç»ˆæ­¢

æŸä¸ªè¿›ç¨‹æ— æ³•æ­£å¸¸ç»ˆæ­¢ã€‚

```bash
# DIAGNOSE:
ps aux | grep <process-name>
# Note the PID

# ESCALATION LADDER:
kill <pid>                # SIGTERM (graceful shutdown)
sleep 5
kill -9 <pid>             # SIGKILL (cannot be caught, immediate death)

# If SIGKILL doesn't work, it's a zombie or kernel-stuck process:
# Check if zombie:
ps aux | grep <pid>
# State "Z" = zombie. The parent must reap it:
kill -SIGCHLD $(ps -o ppid= -p <pid>)
# Or kill the parent process

# If truly stuck in kernel (state "D"):
# Only a reboot will fix it. The process is stuck in an I/O syscall.

# MASS CLEANUP: Kill all processes matching a name
pkill -f <pattern>          # Graceful
pkill -9 -f <pattern>      # Force
```

### å†…å­˜ä¸è¶³ï¼ˆæ“ä½œç³»ç»Ÿè§¦å‘ OOMï¼‰

ç³»ç»Ÿå› å†…å­˜ä¸è¶³è€Œè‡ªåŠ¨å…³é—­è¿›ç¨‹ã€‚

```bash
# DIAGNOSE: Was your process OOM-killed?
dmesg | grep -i "oom\|killed process" | tail -20
journalctl -k | grep -i "oom\|killed" | tail -20

# Check what's using memory right now:
ps aux --sort=-%mem | head -20        # Top memory consumers
free -h                                 # System memory overview

# FIX: Free memory immediately
# 1. Kill the biggest consumer (if safe to do so)
kill $(ps aux --sort=-%mem | awk 'NR==2{print $2}')

# 2. Drop filesystem caches (safe, no data loss)
sync && echo 3 | sudo tee /proc/sys/vm/drop_caches

# 3. Disable swap thrashing (if swap is full)
sudo swapoff -a && sudo swapon -a

# PREVENT: Set memory limits
# Docker:
docker run --memory=512m --memory-swap=1g myapp

# Systemd service:
# Add to [Service] section:
# MemoryMax=512M
# MemoryHigh=400M

# Node.js:
node --max-old-space-size=512 app.js

# VERIFY:
free -h
ps aux --sort=-%mem | head -5
```

## æ•°æ®åº“ç›¸å…³ç´§æ€¥æƒ…å†µ

### è¿ç§»æ“ä½œå¤±è´¥ï¼ˆéƒ¨åˆ†æ•°æ®æœªæ­£ç¡®åº”ç”¨ï¼‰

æ•°æ®åº“è¿ç§»æ“ä½œå¤±è´¥ï¼Œå¯¼è‡´æ•°æ®ä¸ä¸€è‡´ã€‚

```bash
# DIAGNOSE: What state is the database in?
# Check which migrations have run:

# Rails:
rails db:migrate:status

# Django:
python manage.py showmigrations

# Knex/Node:
npx knex migrate:status

# Prisma:
npx prisma migrate status

# Raw SQL â€” check migration table:
# PostgreSQL/MySQL:
SELECT * FROM schema_migrations ORDER BY version DESC LIMIT 10;
# Or: SELECT * FROM _migrations ORDER BY id DESC LIMIT 10;

# FIX: Roll back the failed migration
# Most frameworks track migration state. Roll back to last good state:

# Rails:
rails db:rollback STEP=1

# Django:
python manage.py migrate <app_name> <previous_migration_number>

# Knex:
npx knex migrate:rollback

# FIX (manual): If the framework is confused about state:
# 1. Check what the migration actually did
# 2. Manually undo partial changes
# 3. Delete the migration record from the migrations table
# 4. Fix the migration code
# 5. Re-run

# VERIFY:
# Run the migration again and confirm it applies cleanly
# Check the affected tables/columns exist correctly
```

### è¯¯åˆ é™¤äº†è¡¨æˆ–æ•´ä¸ªæ•°æ®åº“

ä¸å°å¿ƒåˆ é™¤äº†æ•°æ®åº“ä¸­çš„è¡¨æˆ–æ•´ä¸ªæ•°æ®åº“ã€‚

```bash
# PostgreSQL:
# If you have WAL archiving / point-in-time recovery configured:
pg_restore -d mydb /backups/latest.dump -t dropped_table

# If no backup exists, check if the transaction is still open:
# (Only works if you haven't committed yet)
# Just run ROLLBACK; in your SQL session.

# MySQL:
# If binary logging is enabled:
mysqlbinlog /var/log/mysql/mysql-bin.000001 \
  --start-datetime="2026-02-03 10:00:00" \
  --stop-datetime="2026-02-03 10:30:00" > recovery.sql
# Review recovery.sql, then apply

# SQLite:
# If the file still exists, it's fine â€” SQLite DROP TABLE is within the file
# Restore from backup:
cp /backups/db.sqlite3 ./db.sqlite3

# PREVENTION: Always run destructive SQL in a transaction
BEGIN;
DROP TABLE users;  -- oops
ROLLBACK;          -- saved
```

### æ•°æ®åº“è¢«é”å®šæˆ–å‡ºç°æ­»é”

æ•°æ®åº“æ“ä½œè¢«é˜»å¡ï¼Œæ— æ³•æ­£å¸¸è®¿é—®ã€‚

```bash
# PostgreSQL:
-- Find blocking queries
SELECT pid, usename, state, query, wait_event_type, query_start
FROM pg_stat_activity
WHERE state != 'idle'
ORDER BY query_start;

-- Find locks
SELECT blocked_locks.pid AS blocked_pid,
       blocking_locks.pid AS blocking_pid,
       blocked_activity.query AS blocked_query,
       blocking_activity.query AS blocking_query
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks ON blocking_locks.locktype = blocked_locks.locktype
JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted;

-- Kill blocking query
SELECT pg_terminate_backend(<blocking_pid>);

# MySQL:
SHOW PROCESSLIST;
SHOW ENGINE INNODB STATUS\G  -- Look for "LATEST DETECTED DEADLOCK"
KILL <process_id>;

# SQLite:
# SQLite uses file-level locking. Common fix:
# 1. Find and close all connections
# 2. Check for .db-journal or .db-wal files (active transactions)
# 3. If stuck: cp database.db database-fixed.db && mv database-fixed.db database.db
# This forces SQLite to release the lock by creating a fresh file handle

# VERIFY:
# Run a simple query to confirm database is responsive
SELECT 1;
```

### è¿æ¥æ± è€—å°½

æ•°æ®åº“è¿æ¥æ± ä¸­çš„è¿æ¥èµ„æºè¢«è€—å°½ã€‚

```bash
# DIAGNOSE:
# Error messages like: "too many connections", "connection pool exhausted",
# "FATAL: remaining connection slots are reserved for superuser"

# PostgreSQL â€” check connection count:
SELECT count(*), state FROM pg_stat_activity GROUP BY state;
SELECT max_conn, used, max_conn - used AS available
FROM (SELECT count(*) AS used FROM pg_stat_activity) t,
     (SELECT setting::int AS max_conn FROM pg_settings WHERE name='max_connections') m;

# FIX: Kill idle connections
-- Terminate idle connections older than 5 minutes
SELECT pg_terminate_backend(pid)
FROM pg_stat_activity
WHERE state = 'idle'
AND query_start < now() - interval '5 minutes';

# FIX: Increase max connections (requires restart)
# postgresql.conf:
# max_connections = 200  (default is 100)

# BETTER FIX: Use a connection pooler
# PgBouncer or pgcat in front of PostgreSQL
# Application-level: set pool size to match your needs
# Node.js (pg): { max: 20 }
# Python (SQLAlchemy): pool_size=20, max_overflow=10
# Go (database/sql): db.SetMaxOpenConns(20)

# VERIFY:
SELECT count(*) FROM pg_stat_activity;
# Should be well below max_connections
```

## éƒ¨ç½²ç›¸å…³ç´§æ€¥æƒ…å†µ

### å¿«é€Ÿå›æ»šéƒ¨ç½²

éœ€è¦ç«‹å³å›æ»šåˆšåˆšå®Œæˆçš„éƒ¨ç½²æ“ä½œã€‚

```bash
# Git-based deploys:
git log --oneline -5 origin/main
git revert HEAD                    # Create a revert commit
git push origin main               # Deploy the revert
# Revert is safer than reset because it preserves history

# Docker/container deploys:
# Roll back to previous image tag
docker pull myapp:previous-tag
docker stop myapp-current
docker run -d --name myapp myapp:previous-tag

# Kubernetes:
kubectl rollout undo deployment/myapp
kubectl rollout status deployment/myapp    # Watch rollback progress

# Heroku:
heroku releases
heroku rollback v<previous-version>

# AWS ECS:
aws ecs update-service --cluster mycluster --service myservice \
  --task-definition myapp:<previous-revision>

# VERIFY:
# Hit the health check endpoint
curl -s -o /dev/null -w "%{http_code}" https://myapp.example.com/health
# Should return 200
```

### å®¹å™¨æ— æ³•å¯åŠ¨

Docker å®¹å™¨æ— æ³•æ­£å¸¸å¯åŠ¨ã€‚

```bash
# DIAGNOSE: Why did it fail?
docker logs <container-id> --tail 100
docker inspect <container-id> | grep -A5 "State"

# Common causes and fixes:

# 1. "exec format error" â€” wrong platform (built for arm64, running on amd64)
docker build --platform linux/amd64 -t myapp .

# 2. "permission denied" â€” file not executable or wrong user
# In Dockerfile:
RUN chmod +x /app/entrypoint.sh
# Or: USER root before the command, then drop back

# 3. "port already allocated" â€” another container or process on that port
docker ps -a | grep <port>
docker stop <conflicting-container>

# 4. "no such file or directory" â€” entrypoint or CMD path is wrong
docker run -it --entrypoint sh myapp  # Get a shell to debug
ls -la /app/                           # Check what's actually there

# 5. Healthcheck failing â†’ container keeps restarting
docker inspect <container-id> --format='{{json .State.Health}}'
# Temporarily disable healthcheck to get logs:
docker run --no-healthcheck myapp

# 6. Out of memory â€” container OOM killed
docker inspect <container-id> --format='{{.State.OOMKilled}}'
# If true: docker run --memory=1g myapp

# VERIFY:
docker ps  # Container should show "Up" status
docker logs <container-id> --tail 5  # No errors
```

### SSL è¯ä¹¦è¿‡æœŸ

SSL è¯ä¹¦å·²è¿‡æœŸï¼Œå¯¼è‡´è¿æ¥å¤±è´¥ã€‚

```bash
# DIAGNOSE: Check certificate expiry
echo | openssl s_client -connect mysite.com:443 -servername mysite.com 2>/dev/null | \
  openssl x509 -noout -dates
# notAfter shows expiry date

# FIX (Let's Encrypt â€” most common):
sudo certbot renew --force-renewal
sudo systemctl reload nginx   # or: sudo systemctl reload apache2

# FIX (manual certificate):
# 1. Get new certificate from your CA
# 2. Replace files:
sudo cp new-cert.pem /etc/ssl/certs/mysite.pem
sudo cp new-key.pem /etc/ssl/private/mysite.key
# 3. Reload web server
sudo nginx -t && sudo systemctl reload nginx

# FIX (AWS ACM):
# ACM auto-renews if DNS validation is configured.
# If email validation: check the admin email for renewal link
# If stuck: request a new certificate in ACM and update the load balancer

# PREVENTION: Auto-renewal with monitoring
# Cron job to check expiry and alert:
echo '0 9 * * 1 echo | openssl s_client -connect mysite.com:443 2>/dev/null | openssl x509 -checkend 604800 -noout || echo "CERT EXPIRES WITHIN 7 DAYS" | mail -s "SSL ALERT" admin@example.com' | crontab -

# VERIFY:
curl -sI https://mysite.com | head -5
# Should return HTTP/2 200, not certificate errors
```

## è®¿é—®æƒé™ç›¸å…³ç´§æ€¥æƒ…å†µ

### SSH è®¿é—®è¢«é”å®š

SSH è®¿é—®è¢«é˜»æ­¢ï¼Œæ— æ³•æ­£å¸¸ç™»å½•ç³»ç»Ÿã€‚

```bash
# DIAGNOSE: Why can't you connect?
ssh -vvv user@host  # Verbose output shows where it fails

# Common causes:

# 1. Key not accepted â€” wrong key, permissions, or authorized_keys issue
ssh -i ~/.ssh/specific_key user@host  # Try explicit key
chmod 600 ~/.ssh/id_rsa               # Fix key permissions
chmod 700 ~/.ssh                       # Fix .ssh dir permissions

# 2. "Connection refused" â€” sshd not running or firewall blocking
# If you have console access (cloud provider's web console):
sudo systemctl start sshd
sudo systemctl status sshd

# 3. Firewall blocking port 22
# Cloud console:
sudo ufw allow 22/tcp       # Ubuntu
sudo firewall-cmd --add-service=ssh --permanent && sudo firewall-cmd --reload  # CentOS

# 4. Changed SSH port and forgot
# Try common alternate ports:
ssh -p 2222 user@host
ssh -p 22222 user@host
# Or check from console: grep -i port /etc/ssh/sshd_config

# 5. IP changed / DNS stale
ping hostname    # Verify IP resolution
ssh user@<direct-ip>  # Try IP instead of hostname

# 6. Locked out after too many attempts (fail2ban)
# From console:
sudo fail2ban-client set sshd unbanip <your-ip>
# Or wait for the ban to expire (usually 10 min)

# CLOUD PROVIDER ESCAPE HATCHES:
# AWS: EC2 â†’ Instance â†’ Connect â†’ Session Manager (no SSH needed)
# GCP: Compute â†’ VM instances â†’ SSH (browser-based)
# Azure: VM â†’ Serial console
# DigitalOcean: Droplet â†’ Access â†’ Console

# VERIFY:
ssh user@host echo "connection works"
```

### sudo æƒé™ä¸¢å¤±

ç”¨æˆ·å¤±å»äº† `sudo` æƒé™ï¼Œæ— æ³•æ‰§è¡Œç®¡ç†å‘½ä»¤ã€‚

```bash
# If you have physical/console access:
# 1. Boot into single-user/recovery mode
#    - Reboot, hold Shift (GRUB), select "recovery mode"
#    - Or add init=/bin/bash to kernel command line

# 2. Remount filesystem read-write
mount -o remount,rw /

# 3. Fix sudo access
usermod -aG sudo <username>    # Debian/Ubuntu
usermod -aG wheel <username>   # CentOS/RHEL
# Or edit directly:
visudo
# Add: username ALL=(ALL:ALL) ALL

# 4. Reboot normally
reboot

# If you have another sudo/root user:
su - other-admin
sudo usermod -aG sudo <locked-user>

# CLOUD: Use the provider's console or reset the instance
# AWS: Create an AMI, launch new instance, mount old root volume, fix
```

## ç½‘ç»œç›¸å…³ç´§æ€¥æƒ…å†µ

### å…¨å±€ç½‘ç»œæ•…éšœ

æ•´ä¸ªç½‘ç»œæ— æ³•æ­£å¸¸é€šä¿¡ã€‚

```bash
# DIAGNOSE: Isolate the layer
# 1. Is the network interface up?
ip addr show         # or: ifconfig
ping 127.0.0.1       # Loopback works?

# 2. Can you reach the gateway?
ip route | grep default
ping <gateway-ip>

# 3. Can you reach the internet by IP?
ping 8.8.8.8          # Google DNS
ping 1.1.1.1          # Cloudflare DNS

# 4. Is DNS working?
nslookup google.com
dig google.com

# DECISION TREE:
# ping 127.0.0.1 fails      â†’ network stack broken, restart networking
# ping gateway fails         â†’ local network issue (cable, wifi, DHCP)
# ping 8.8.8.8 fails        â†’ routing/firewall issue
# ping 8.8.8.8 works but    â†’ DNS issue
#   nslookup fails

# FIX: DNS broken
echo "nameserver 8.8.8.8" | sudo tee /etc/resolv.conf
# Or: sudo systemd-resolve --flush-caches

# FIX: Interface down
sudo ip link set eth0 up
sudo dhclient eth0        # Request new DHCP lease

# FIX: Restart networking entirely
sudo systemctl restart NetworkManager    # Desktop Linux
sudo systemctl restart networking        # Server
sudo systemctl restart systemd-networkd  # Systemd-based

# Docker: Container can't reach the internet
docker run --rm alpine ping 8.8.8.8  # Test from container
# If fails:
sudo systemctl restart docker    # Often fixes Docker networking
# Or: docker network prune
```

### DNS æ›´æ–°å¤±è´¥

DNS æœåŠ¡å™¨æ— æ³•æ­£ç¡®æ›´æ–°åŸŸåè§£æä¿¡æ¯ã€‚

```bash
# DIAGNOSE: Check what different DNS servers see
dig @8.8.8.8 mysite.com        # Google
dig @1.1.1.1 mysite.com        # Cloudflare
dig @ns1.yourdns.com mysite.com # Authoritative nameserver

# Check TTL (time remaining before caches expire):
dig mysite.com | grep -i ttl

# REALITY CHECK:
# DNS propagation takes time. TTL controls this.
# TTL 300 = 5 minutes. TTL 86400 = 24 hours.
# You cannot speed this up. You can only wait.

# FIX: If authoritative nameserver has wrong records
# Update the record at your DNS provider (Cloudflare, Route53, etc.)
# Then flush your local cache:
# macOS:
sudo dscacheutil -flushcache && sudo killall -HUP mDNSResponder
# Linux:
sudo systemd-resolve --flush-caches
# Windows:
ipconfig /flushdns

# WORKAROUND: While waiting for propagation
# Add to /etc/hosts for immediate local effect:
echo "93.184.216.34 mysite.com" | sudo tee -a /etc/hosts
# Remove this after propagation completes!

# VERIFY:
dig +short mysite.com  # Should show new IP/record
```

## æ–‡ä»¶ç›¸å…³ç´§æ€¥æƒ…å†µ

### è¯¯åˆ æ–‡ä»¶ï¼ˆæœªä¿å­˜åœ¨ Git ä»“åº“ä¸­ï¼‰

æ–‡ä»¶è¢«æ„å¤–åˆ é™¤ï¼Œä½†æœªä¿å­˜åœ¨ Git ä»“åº“ä¸­ã€‚

```bash
# DIAGNOSE: Are the files recoverable?

# If the process still has the file open:
lsof | grep deleted
# Then recover from /proc:
cp /proc/<pid>/fd/<fd-number> /path/to/restored-file

# If recently deleted on ext4 (Linux):
# Install extundelete or testdisk
sudo extundelete /dev/sda1 --restore-file path/to/file
# Or use testdisk interactively for a better UI

# macOS:
# Check Trash first: ~/.Trash/
# Time Machine: tmutil restore /path/to/file

# PREVENTION:
# Use trash-cli instead of rm:
# npm install -g trash-cli
# trash file.txt  (moves to trash instead of permanent delete)
# Or alias: alias rm='echo "Use trash instead"; false'
```

### æƒé™è®¾ç½®é”™è¯¯

æ–‡ä»¶æƒé™è¢«é”™è¯¯åœ°åº”ç”¨åˆ°äº†æ•´ä¸ªç›®å½•æˆ–æ–‡ä»¶ä¸Šã€‚

```bash
# "I ran chmod -R 777 /" or "chmod -R 000 /important/dir"

# FIX: Common default permissions
# For a web project:
find /path -type d -exec chmod 755 {} \;  # Directories: rwxr-xr-x
find /path -type f -exec chmod 644 {} \;  # Files: rw-r--r--
find /path -name "*.sh" -exec chmod 755 {} \;  # Scripts: executable

# For SSH:
chmod 700 ~/.ssh
chmod 600 ~/.ssh/id_rsa
chmod 644 ~/.ssh/id_rsa.pub
chmod 600 ~/.ssh/authorized_keys
chmod 644 ~/.ssh/config

# For a system directory (âš ï¸ serious â€” may need rescue boot):
# If /etc permissions are broken:
# Boot from live USB, mount the drive, fix permissions
# Reference: dpkg --verify (Debian) or rpm -Va (RHEL) to compare against package defaults

# VERIFY:
ls -la /path/to/fixed/directory
```

## é€šç”¨è¯Šæ–­å·¥å…·

å½“æ— æ³•ç¡®å®šé—®é¢˜æ‰€åœ¨æ—¶ï¼Œå¯ä»¥è¿è¡Œä»¥ä¸‹è¯Šæ–­å‘½ä»¤ï¼š

```bash
#!/bin/bash
# emergency-diagnostic.sh â€” Quick system health check

echo "=== DISK ==="
df -h | grep -E '^/|Filesystem'

echo -e "\n=== MEMORY ==="
free -h

echo -e "\n=== CPU / LOAD ==="
uptime

echo -e "\n=== TOP PROCESSES (by CPU) ==="
ps aux --sort=-%cpu | head -6

echo -e "\n=== TOP PROCESSES (by MEM) ==="
ps aux --sort=-%mem | head -6

echo -e "\n=== NETWORK ==="
ping -c 1 -W 2 8.8.8.8 > /dev/null 2>&1 && echo "Internet: OK" || echo "Internet: UNREACHABLE"
ping -c 1 -W 2 $(ip route | awk '/default/{print $3}') > /dev/null 2>&1 && echo "Gateway: OK" || echo "Gateway: UNREACHABLE"

echo -e "\n=== RECENT ERRORS ==="
journalctl -p err --since "1 hour ago" --no-pager | tail -20 2>/dev/null || \
  dmesg | tail -20

echo -e "\n=== DOCKER (if running) ==="
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" 2>/dev/null || echo "Docker not running"
docker system df 2>/dev/null || true

echo -e "\n=== LISTENING PORTS ==="
ss -tlnp 2>/dev/null | head -15 || netstat -tlnp 2>/dev/null | head -15

echo -e "\n=== FAILED SERVICES ==="
systemctl --failed 2>/dev/null || true
```

è¿è¡Œè¯¥å‘½ä»¤åï¼Œè¯·æŸ¥çœ‹è¾“å‡ºç»“æœï¼Œç„¶åæ ¹æ®è¾“å‡ºå†…å®¹è·³è½¬åˆ°ç›¸åº”çš„å¤„ç†æµç¨‹ã€‚

## æç¤º

- **åœ¨æ¸…ç† Git å†å²è®°å½•ä¹‹å‰ï¼Œå…ˆæ’¤é”€ç›¸å…³å‡­è¯ã€‚** ä¸€æ—¦æ•æ„Ÿä¿¡æ¯è¢«å…¬å¼€æäº¤ï¼Œè‡ªåŠ¨åŒ–ç›‘æ§å·¥å…·ä¼šåœ¨å‡ åˆ†é’Ÿå†…å‘ç°ã€‚è™½ç„¶æ¸…ç†å†å²è®°å½•å¾ˆé‡è¦ï¼Œä½†æ’¤é”€å‡­è¯æ˜¯æ›´ç´§è¿«çš„ä»»åŠ¡ã€‚
- **`git reflog` æ˜¯ä½ çš„â€œæ’¤é”€æŒ‰é’®â€ã€‚** å®ƒä¼šè®°å½•è¿‡å» 30 å¤©å†…çš„æ‰€æœ‰åˆ†æ”¯åˆ‡æ¢è®°å½•ï¼ˆHEAD çš„ç§»åŠ¨å†å²ï¼‰ã€‚å¦‚æœæäº¤äº†é”™è¯¯çš„æäº¤æˆ–æ‰§è¡Œäº†é”™è¯¯çš„ `git rebase` æ“ä½œï¼Œ`git reflog` ä¸­ä¼šä¿å­˜ç›¸åº”çš„æ¢å¤æ“ä½œä¿¡æ¯ã€‚å­¦ä¼šå¦‚ä½•ä½¿ç”¨å®ƒã€‚
- **æˆªæ–­æ—¥å¿—æ–‡ä»¶ï¼Œè€Œä¸æ˜¯ç›´æ¥åˆ é™¤å®ƒä»¬ã€‚** ä½¿ç”¨ `truncate -s 0 file.log` å¯ä»¥ç«‹å³é‡Šæ”¾ç£ç›˜ç©ºé—´ï¼ŒåŒæ—¶ä¿ç•™æ–‡ä»¶çš„æ‰“å¼€çŠ¶æ€ã€‚å¦‚æœè¿›ç¨‹ä»åœ¨ä½¿ç”¨è¯¥æ—¥å¿—æ–‡ä»¶ï¼Œç›´æ¥åˆ é™¤ä¼šå¯¼è‡´ç©ºé—´æ— æ³•ç«‹å³é‡Šæ”¾ã€‚
- **å§‹ç»ˆä½¿ç”¨ `--force-with-lease` è€Œä¸æ˜¯ `--force`ã€‚** è¿™ä¸ªé€‰é¡¹å¯ä»¥é˜²æ­¢åœ¨ä»–äººå·²ç»æ¨é€ä»£ç çš„æƒ…å†µä¸‹è¦†ç›–ä»–ä»¬çš„ä¿®æ”¹ã€‚
- **æ¯ä¸ªæ¢å¤æ“ä½œéƒ½åº”åŒ…å«éªŒè¯æ­¥éª¤ã€‚** è¿è¡Œè¯Šæ–­å‘½ä»¤åï¼ŒåŠ¡å¿…æ£€æŸ¥è¾“å‡ºç»“æœï¼Œç¡®è®¤ä¿®å¤æ“ä½œæ˜¯å¦æœ‰æ•ˆã€‚åˆ‡å‹¿ç›²ç›®ç›¸ä¿¡ç»“æœã€‚
- **Docker æ˜¯å¼€å‘è€…æœºå™¨ä¸Šæœ€å¤§çš„ç£ç›˜ç©ºé—´å ç”¨è€…ã€‚** åœ¨å¼€å‘ç¯å¢ƒä¸­ï¼Œæ‰§è¡Œ `docker system prune -a` å‘½ä»¤é€šå¸¸å¾ˆå®‰å…¨ï¼Œå¯ä»¥é‡Šæ”¾å¤§é‡ç£ç›˜ç©ºé—´ã€‚
- **åœ¨å¤„ç†æ•°æ®åº“ç´§æ€¥æƒ…å†µæ—¶ï¼Œå°†å…·æœ‰ç ´åæ€§çš„æ“ä½œå°è£…åœ¨äº‹åŠ¡ä¸­ã€‚** ä½¿ç”¨ `BEGIN; DROP TABLE users; ROLLBACK;` å¯ä»¥ç¡®ä¿æ•°æ®å®‰å…¨ã€‚è®°ä½è¿™ä¸ªæ“ä½œçš„é‡è¦æ€§ã€‚
- **å½“ SSH è®¿é—®è¢«é”å®šæ—¶ï¼Œæ¯ä¸ªäº‘æœåŠ¡æä¾›å•†éƒ½æä¾›äº†ç›¸åº”çš„åº”æ€¥è§£å†³æ–¹æ¡ˆã€‚** AWS æä¾›äº† Session Managerï¼ŒGCP æä¾›äº†æµè§ˆå™¨ SSH è¿æ¥ï¼ŒAzure æä¾›äº† Serial Consoleã€‚åœ¨éœ€è¦ä½¿ç”¨è¿™äº›å·¥å…·ä¹‹å‰ï¼Œè¯·å…ˆäº†è§£å®ƒä»¬çš„ä½¿ç”¨æ–¹æ³•ã€‚
- **æ“ä½œé¡ºåºè‡³å…³é‡è¦ï¼šè¯Šæ–­ â†’ ä¿®å¤ â†’ éªŒè¯ã€‚** è·³è¿‡è¯Šæ–­æ­¥éª¤å¯èƒ½ä¼šå¯¼è‡´é”™è¯¯çš„ä¿®å¤ï¼›è·³è¿‡éªŒè¯æ­¥éª¤åˆ™å¯èƒ½å¯¼è‡´é”™è¯¯çš„åˆ¤æ–­ã€‚åŠ¡å¿…ä¸¥æ ¼æŒ‰ç…§è¿™ä¸ªé¡ºåºæ“ä½œã€‚
- **è¯·ç¡®ä¿è¿™ä¸ªå·¥å…·åŒ…å§‹ç»ˆå®‰è£…åœ¨ä½ çš„å¼€å‘ç¯å¢ƒä¸­ã€‚** åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ä½ å¯èƒ½ç”¨ä¸åˆ°å®ƒï¼Œä½†ä¸€æ—¦éœ€è¦æ—¶ï¼Œå®ƒä¼šç«‹åˆ»æ´¾ä¸Šç”¨åœºã€‚