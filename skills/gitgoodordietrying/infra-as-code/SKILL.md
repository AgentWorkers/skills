---
name: infra-as-code
description: ä½¿ç”¨ä»£ç æ¥å®šä¹‰å’Œç®¡ç†äº‘åŸºç¡€è®¾æ–½ã€‚è¿™åœ¨ç¼–å†™ Terraformã€CloudFormation æˆ– Pulumi é…ç½®æ–‡ä»¶æ—¶éå¸¸æœ‰ç”¨ï¼Œå¯ä»¥å¸®åŠ©ä½ ç®¡ç†åŸºç¡€è®¾æ–½çš„çŠ¶æ€ã€è§„åˆ’éƒ¨ç½²ã€é…ç½®ç½‘ç»œ/è®¡ç®—/å­˜å‚¨èµ„æºï¼Œä»¥åŠæ’æŸ¥åŸºç¡€è®¾æ–½é…ç½®çš„å·®å¼‚ï¼ˆå³åŸºç¡€è®¾æ–½ä¸é¢„æœŸé…ç½®ä¹‹é—´çš„ä¸ä¸€è‡´ï¼‰ã€‚
metadata: {"clawdbot":{"emoji":"ğŸ—ï¸","requires":{"anyBins":["terraform","aws","pulumi"]},"os":["linux","darwin","win32"]}}
---

# åŸºç¡€è®¾æ–½å³ä»£ç ï¼ˆInfrastructure as Codeï¼‰

é€šè¿‡å£°æ˜å¼é…ç½®æ¥å®šä¹‰ã€éƒ¨ç½²å’Œç®¡ç†äº‘åŸºç¡€è®¾æ–½ã€‚æ¶µç›–Terraformï¼ˆæ”¯æŒå¤šäº‘å¹³å°ï¼‰ã€AWS CloudFormationå’ŒPulumiï¼ˆä»¥ä»£ç ä¸ºä¸­å¿ƒçš„åŸºç¡€è®¾æ–½ç®¡ç†å·¥å…·ï¼‰ï¼Œå¹¶æä¾›äº†é’ˆå¯¹è®¡ç®—ã€ç½‘ç»œã€å­˜å‚¨ã€æ•°æ®åº“å’ŒçŠ¶æ€ç®¡ç†çš„æœ€ä½³å®è·µã€‚

## ä½¿ç”¨åœºæ™¯

- è®¾ç½®äº‘åŸºç¡€è®¾æ–½ï¼ˆVPCã€EC2å®ä¾‹ã€Lambdaå‡½æ•°ã€S3å­˜å‚¨ã€RDSæ•°æ®åº“ç­‰ï¼‰
- ç¼–å†™æˆ–ä¿®æ”¹Terraformé…ç½®æ–‡ä»¶
- ç®¡ç†Terraformçš„çŠ¶æ€æ•°æ®ï¼ˆè¿œç¨‹å­˜å‚¨ã€å·¥ä½œåŒºè®¾ç½®ã€é…ç½®å¯¼å…¥ç­‰ï¼‰
- åˆ›å»ºCloudFormationæ¨¡æ¿
- ä½¿ç”¨Pulumiè¿›è¡ŒTypeScript/Python/Goè¯­è¨€çš„åŸºç¡€è®¾æ–½ç®¡ç†
- å®‰å…¨åœ°è§„åˆ’å’Œé¢„è§ˆåŸºç¡€è®¾æ–½å˜æ›´
- æŸ¥æ‰¾å£°æ˜çŠ¶æ€ä¸å®é™…èµ„æºä¹‹é—´çš„å·®å¼‚
- è®¾ç½®å¤šç¯å¢ƒéƒ¨ç½²ï¼ˆå¼€å‘ç¯å¢ƒã€æµ‹è¯•ç¯å¢ƒã€ç”Ÿäº§ç¯å¢ƒï¼‰

## Terraform

### å¿«é€Ÿå…¥é—¨

```bash
# Install: https://developer.hashicorp.com/terraform/install

# Initialize a project
mkdir infra && cd infra
terraform init

# Core workflow
terraform plan        # Preview changes (safe, read-only)
terraform apply       # Apply changes (creates/modifies resources)
terraform destroy     # Tear down all resources

# Format and validate
terraform fmt -recursive    # Auto-format all .tf files
terraform validate          # Check syntax and config validity
```

### é¡¹ç›®ç»“æ„

```
infra/
  main.tf              # Primary resources
  variables.tf         # Input variable declarations
  outputs.tf           # Output values
  providers.tf         # Provider configuration
  terraform.tfvars     # Variable values (don't commit secrets)
  backend.tf           # Remote state configuration
  modules/
    vpc/
      main.tf
      variables.tf
      outputs.tf
    compute/
      main.tf
      variables.tf
      outputs.tf
```

### æä¾›è€…é…ç½®ï¼ˆProvider Configurationï¼‰

```hcl
# providers.tf
terraform {
  required_version = ">= 1.5"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = var.aws_region

  default_tags {
    tags = {
      Project     = var.project_name
      Environment = var.environment
      ManagedBy   = "terraform"
    }
  }
}
```

### å˜é‡ä¸è¾“å‡ºï¼ˆVariables and Outputsï¼‰

```hcl
# variables.tf
variable "aws_region" {
  type        = string
  default     = "us-east-1"
  description = "AWS region for all resources"
}

variable "environment" {
  type        = string
  description = "Deployment environment"
  validation {
    condition     = contains(["dev", "staging", "prod"], var.environment)
    error_message = "Environment must be dev, staging, or prod."
  }
}

variable "instance_type" {
  type    = string
  default = "t3.micro"
}

variable "db_password" {
  type      = string
  sensitive = true
  description = "Database password (pass via TF_VAR_db_password env var)"
}

# outputs.tf
output "vpc_id" {
  value       = aws_vpc.main.id
  description = "VPC ID"
}

output "api_endpoint" {
  value = aws_lb.api.dns_name
}
```

### VPCä¸ç½‘ç»œé…ç½®ï¼ˆVPC + Networkingï¼‰

```hcl
# Networking module
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_support   = true
  enable_dns_hostnames = true

  tags = { Name = "${var.project_name}-vpc" }
}

resource "aws_subnet" "public" {
  count             = 2
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.${count.index + 1}.0/24"
  availability_zone = data.aws_availability_zones.available.names[count.index]

  map_public_ip_on_launch = true
  tags = { Name = "${var.project_name}-public-${count.index + 1}" }
}

resource "aws_subnet" "private" {
  count             = 2
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.${count.index + 10}.0/24"
  availability_zone = data.aws_availability_zones.available.names[count.index]

  tags = { Name = "${var.project_name}-private-${count.index + 1}" }
}

resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id
}

resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id
  }
}

resource "aws_route_table_association" "public" {
  count          = 2
  subnet_id      = aws_subnet.public[count.index].id
  route_table_id = aws_route_table.public.id
}

resource "aws_security_group" "web" {
  name_prefix = "${var.project_name}-web-"
  vpc_id      = aws_vpc.main.id

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

data "aws_availability_zones" "available" {
  state = "available"
}
```

### è®¡ç®—èµ„æºç®¡ç†ï¼ˆCompute Resources: EC2ï¼‰

```hcl
resource "aws_instance" "app" {
  ami                    = data.aws_ami.ubuntu.id
  instance_type          = var.instance_type
  subnet_id              = aws_subnet.public[0].id
  vpc_security_group_ids = [aws_security_group.web.id]
  key_name               = var.key_pair_name

  user_data = <<-EOF
    #!/bin/bash
    apt-get update
    apt-get install -y docker.io
    systemctl start docker
    docker run -d -p 80:8080 ${var.docker_image}
  EOF

  tags = { Name = "${var.project_name}-app" }
}

data "aws_ami" "ubuntu" {
  most_recent = true
  owners      = ["099720109477"] # Canonical

  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-*-24.04-amd64-server-*"]
  }
}
```

### S3å­˜å‚¨ä¸é™æ€ç½‘ç«™ï¼ˆS3 Storage + Static Websitesï¼‰

```hcl
resource "aws_s3_bucket" "website" {
  bucket = "${var.project_name}-website"
}

resource "aws_s3_bucket_website_configuration" "website" {
  bucket = aws_s3_bucket.website.id

  index_document { suffix = "index.html" }
  error_document { key = "error.html" }
}

resource "aws_s3_bucket_public_access_block" "website" {
  bucket = aws_s3_bucket.website.id

  block_public_acls       = false
  block_public_policy     = false
  ignore_public_acls      = false
  restrict_public_buckets = false
}

resource "aws_s3_bucket_policy" "website" {
  bucket = aws_s3_bucket.website.id

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Sid       = "PublicRead"
      Effect    = "Allow"
      Principal = "*"
      Action    = "s3:GetObject"
      Resource  = "${aws_s3_bucket.website.arn}/*"
    }]
  })

  depends_on = [aws_s3_bucket_public_access_block.website]
}
```

### RDSæ•°æ®åº“ï¼ˆRDS Databasesï¼‰

```hcl
resource "aws_db_subnet_group" "main" {
  name       = "${var.project_name}-db"
  subnet_ids = aws_subnet.private[*].id
}

resource "aws_security_group" "db" {
  name_prefix = "${var.project_name}-db-"
  vpc_id      = aws_vpc.main.id

  ingress {
    from_port       = 5432
    to_port         = 5432
    protocol        = "tcp"
    security_groups = [aws_security_group.web.id]
  }
}

resource "aws_db_instance" "main" {
  identifier        = "${var.project_name}-db"
  engine            = "postgres"
  engine_version    = "16.1"
  instance_class    = "db.t3.micro"
  allocated_storage = 20

  db_name  = var.db_name
  username = var.db_username
  password = var.db_password

  db_subnet_group_name   = aws_db_subnet_group.main.name
  vpc_security_group_ids = [aws_security_group.db.id]

  backup_retention_period = 7
  skip_final_snapshot     = var.environment != "prod"
  deletion_protection     = var.environment == "prod"
}
```

### Lambdaå‡½æ•°ï¼ˆLambda Functionsï¼‰

```hcl
data "archive_file" "lambda_zip" {
  type        = "zip"
  source_dir  = "${path.module}/lambda"
  output_path = "${path.module}/lambda.zip"
}

resource "aws_lambda_function" "api" {
  function_name    = "${var.project_name}-api"
  filename         = data.archive_file.lambda_zip.output_path
  source_code_hash = data.archive_file.lambda_zip.output_base64sha256
  handler          = "index.handler"
  runtime          = "nodejs20.x"
  timeout          = 30

  role = aws_iam_role.lambda_exec.arn

  environment {
    variables = {
      DB_HOST     = aws_db_instance.main.endpoint
      ENVIRONMENT = var.environment
    }
  }
}

resource "aws_iam_role" "lambda_exec" {
  name = "${var.project_name}-lambda-exec"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = { Service = "lambda.amazonaws.com" }
    }]
  })
}

resource "aws_iam_role_policy_attachment" "lambda_basic" {
  role       = aws_iam_role.lambda_exec.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
}
```

### çŠ¶æ€ç®¡ç†ï¼ˆState Managementï¼‰

```hcl
# backend.tf - Remote state in S3
terraform {
  backend "s3" {
    bucket         = "my-terraform-state"
    key            = "project/terraform.tfstate"
    region         = "us-east-1"
    dynamodb_table = "terraform-locks"
    encrypt        = true
  }
}
```

### å¤šç¯å¢ƒéƒ¨ç½²æ¨¡å¼ï¼ˆMulti-Environment Deployment Patternsï¼‰

```hcl
# Use workspaces + tfvars files
# terraform.tfvars (default)
# env/dev.tfvars
# env/staging.tfvars
# env/prod.tfvars

# Apply for specific environment
# terraform apply -var-file=env/prod.tfvars
```

```bash
# Environment-specific apply
ENV=${1:-dev}
terraform workspace select "$ENV" || terraform workspace new "$ENV"
terraform apply -var-file="env/$ENV.tfvars"
```

## AWS CloudFormation

### æ¨¡æ¿ç»“æ„ï¼ˆTemplate Structureï¼‰

```yaml
# cloudformation.yaml
AWSTemplateFormatVersion: '2010-09-09'
Description: My application stack

Parameters:
  Environment:
    Type: String
    AllowedValues: [dev, staging, prod]
    Default: dev
  InstanceType:
    Type: String
    Default: t3.micro

Conditions:
  IsProd: !Equals [!Ref Environment, prod]

Resources:
  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsSupport: true
      EnableDnsHostnames: true
      Tags:
        - Key: Name
          Value: !Sub "${AWS::StackName}-vpc"

  PublicSubnet:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: 10.0.1.0/24
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub "${AWS::StackName}-public"

  AppInstance:
    Type: AWS::EC2::Instance
    Properties:
      InstanceType: !Ref InstanceType
      SubnetId: !Ref PublicSubnet
      ImageId: !FindInMap [RegionAMI, !Ref "AWS::Region", ubuntu]

  Database:
    Type: AWS::RDS::DBInstance
    Condition: IsProd
    DeletionPolicy: Snapshot
    Properties:
      Engine: postgres
      DBInstanceClass: db.t3.micro
      AllocatedStorage: 20
      MasterUsername: admin
      MasterUserPassword: !Ref DBPassword

Outputs:
  VpcId:
    Value: !Ref VPC
    Export:
      Name: !Sub "${AWS::StackName}-VpcId"
  InstanceIP:
    Value: !GetAtt AppInstance.PublicIp
```

### CloudFormationå‘½ä»¤è¡Œå·¥å…·ï¼ˆCloudFormation CLIï¼‰

```bash
# Validate template
aws cloudformation validate-template --template-body file://cloudformation.yaml

# Create stack
aws cloudformation create-stack \
  --stack-name myapp-dev \
  --template-body file://cloudformation.yaml \
  --parameters ParameterKey=Environment,ParameterValue=dev \
  --capabilities CAPABILITY_IAM

# Update stack
aws cloudformation update-stack \
  --stack-name myapp-dev \
  --template-body file://cloudformation.yaml \
  --parameters ParameterKey=Environment,ParameterValue=dev

# Preview changes (changeset)
aws cloudformation create-change-set \
  --stack-name myapp-dev \
  --change-set-name update-1 \
  --template-body file://cloudformation.yaml

aws cloudformation describe-change-set \
  --stack-name myapp-dev \
  --change-set-name update-1

# Delete stack
aws cloudformation delete-stack --stack-name myapp-dev

# List stacks
aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE

# Stack events (debugging)
aws cloudformation describe-stack-events --stack-name myapp-dev | head -50
```

## Pulumiï¼ˆåŸºäºä»£ç çš„åŸºç¡€è®¾æ–½ç®¡ç†ï¼‰

### TypeScriptè¯­è¨€å¿«é€Ÿå…¥é—¨ï¼ˆPulumi with TypeScriptï¼‰

```bash
# Install: https://www.pulumi.com/docs/install/
pulumi new aws-typescript

# Core workflow
pulumi preview    # Preview changes
pulumi up         # Apply changes
pulumi destroy    # Tear down
pulumi stack ls   # List stacks
```

### TypeScriptç¤ºä¾‹ï¼ˆTypeScript Exampleï¼‰

```typescript
// index.ts
import * as pulumi from "@pulumi/pulumi";
import * as aws from "@pulumi/aws";

const config = new pulumi.Config();
const environment = config.require("environment");

// VPC
const vpc = new aws.ec2.Vpc("main", {
  cidrBlock: "10.0.0.0/16",
  enableDnsSupport: true,
  enableDnsHostnames: true,
  tags: { Name: `myapp-${environment}-vpc` },
});

// Public subnet
const publicSubnet = new aws.ec2.Subnet("public", {
  vpcId: vpc.id,
  cidrBlock: "10.0.1.0/24",
  mapPublicIpOnLaunch: true,
  tags: { Name: `myapp-${environment}-public` },
});

// S3 bucket
const bucket = new aws.s3.Bucket("data", {
  bucket: `myapp-${environment}-data`,
  versioning: { enabled: true },
});

// Lambda function
const lambdaRole = new aws.iam.Role("lambda-role", {
  assumeRolePolicy: JSON.stringify({
    Version: "2012-10-17",
    Statement: [{
      Action: "sts:AssumeRole",
      Effect: "Allow",
      Principal: { Service: "lambda.amazonaws.com" },
    }],
  }),
});

const lambdaFunc = new aws.lambda.Function("api", {
  runtime: "nodejs20.x",
  handler: "index.handler",
  role: lambdaRole.arn,
  code: new pulumi.asset.FileArchive("./lambda"),
  environment: {
    variables: {
      BUCKET_NAME: bucket.id,
      ENVIRONMENT: environment,
    },
  },
});

// Outputs
export const vpcId = vpc.id;
export const bucketName = bucket.id;
export const lambdaArn = lambdaFunc.arn;
```

### Pythonç¤ºä¾‹ï¼ˆPython Exampleï¼‰

```python
# __main__.py
import pulumi
import pulumi_aws as aws

config = pulumi.Config()
environment = config.require("environment")

vpc = aws.ec2.Vpc("main",
    cidr_block="10.0.0.0/16",
    enable_dns_support=True,
    enable_dns_hostnames=True,
    tags={"Name": f"myapp-{environment}-vpc"})

bucket = aws.s3.Bucket("data",
    bucket=f"myapp-{environment}-data",
    versioning=aws.s3.BucketVersioningArgs(enabled=True))

pulumi.export("vpc_id", vpc.id)
pulumi.export("bucket_name", bucket.id)
```

### Pulumiçš„çŠ¶æ€ç®¡ç†ä¸èµ„æºå †æ ˆï¼ˆPulumi State and Resource Stacksï¼‰

```bash
# Create per-environment stacks
pulumi stack init dev
pulumi stack init staging
pulumi stack init prod

# Switch stack
pulumi stack select dev

# Set config per stack
pulumi config set environment dev
pulumi config set aws:region us-east-1
pulumi config set --secret dbPassword 'my-secret-pass'

# Stack references (cross-stack)
# In consuming stack:
const infra = new pulumi.StackReference("org/infra/prod");
const vpcId = infra.getOutput("vpcId");
```

## åŸºç¡€è®¾æ–½è°ƒè¯•ï¼ˆInfrastructure Debuggingï¼‰

### Terraformè®¡åˆ’æ‰§è¡Œé—®é¢˜ï¼ˆTerraform Plan Execution Issuesï¼‰

```bash
# Detailed plan output
terraform plan -out=plan.tfplan
terraform show plan.tfplan
terraform show -json plan.tfplan | jq '.resource_changes[] | {address, change: .change.actions}'

# Debug mode
TF_LOG=DEBUG terraform plan 2> debug.log

# Check for drift
terraform plan -refresh-only

# Force refresh state
terraform apply -refresh-only
```

### å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ³•ï¼ˆCommon Issues and Solutionsï¼‰

```bash
# Resource stuck in "tainted" state
terraform untaint aws_instance.app

# State locked (another apply running or crashed)
terraform force-unlock LOCK_ID

# Provider version conflict
terraform providers lock    # Generate lock file
terraform init -upgrade     # Upgrade providers

# Circular dependency
# Error: "Cycle" in terraform plan
# Fix: use depends_on explicitly, or break the cycle with data sources
```

### æˆæœ¬ä¼°ç®—ï¼ˆCost Estimationï¼‰

```bash
# Infracost (estimates monthly cost from Terraform plans)
# Install: https://www.infracost.io/docs/
infracost breakdown --path .
infracost diff --path . --compare-to infracost-base.json
```

## ä½¿ç”¨æŠ€å·§

- åœ¨æ‰§è¡Œ`terraform apply`ä¹‹å‰ï¼ŒåŠ¡å¿…å…ˆè¿è¡Œ`terraform plan`å‘½ä»¤ã€‚ä»”ç»†é˜…è¯»è®¡åˆ’è¾“å‡ºç»“æœï¼Œå°¤å…¶æ˜¯åŒ…å«`destroy`æˆ–`replace`æ“ä½œçš„è¡Œã€‚
- ä»é¡¹ç›®å¼€å§‹å°±ä½¿ç”¨è¿œç¨‹çŠ¶æ€å­˜å‚¨æœºåˆ¶ï¼ˆremote stateï¼‰ã€‚æœ¬åœ°çŠ¶æ€æ–‡ä»¶å®¹æ˜“ä¸¢å¤±ã€æ— æ³•å…±äº«ï¼Œä¸”ä¸å…·å¤‡é”å®šæœºåˆ¶ã€‚
- ä¸ºæ‰€æœ‰èµ„æºæ·»åŠ æ ‡ç­¾ï¼ˆè‡³å°‘åŒ…æ‹¬â€œé¡¹ç›®â€ã€â€œç¯å¢ƒâ€å’Œâ€œç®¡ç†è€…â€ç­‰ä¿¡æ¯ï¼‰ã€‚æ ‡ç­¾æœ‰åŠ©äºæˆæœ¬è¿½è¸ªå’Œèµ„æºæ¸…ç†ã€‚
- ç»ä¸è¦å°†æ•æ„Ÿä¿¡æ¯å­˜å‚¨åœ¨`.tf`æ–‡ä»¶æˆ–`terraform.tfvars`ä¸­ï¼Œåº”ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼ˆå¦‚`TF_VAR_NAME`ï¼‰æˆ–ä¸“é—¨çš„å¯†é’¥ç®¡ç†å·¥å…·ï¼ˆå¦‚Vaultï¼‰ã€‚
- ä¸ºå…·æœ‰çŠ¶æ€çš„æ•°æ®èµ„æºï¼ˆå¦‚æ•°æ®åº“ã€åŒ…å«æ•°æ®çš„S3æ¡¶ï¼‰è®¾ç½®`prevent_destroy`ç”Ÿå‘½å‘¨æœŸè§„åˆ™ï¼Œä»¥é˜²æ„å¤–åˆ é™¤ã€‚
- å›ºå®šæä¾›è€…ç‰ˆæœ¬ï¼ˆä½¿ç”¨`~> 5.0`è€Œé`>= 5.0`ï¼‰ï¼Œä»¥é¿å…ç‰ˆæœ¬å‡çº§å¸¦æ¥çš„æ„å¤–é—®é¢˜ã€‚
- åœ¨å¤šç¯å¢ƒéƒ¨ç½²ä¸­ï¼Œå»ºè®®ä½¿ç”¨å·¥ä½œåŒºï¼ˆworkspacesï¼‰å’Œå˜é‡æ–‡ä»¶ï¼ˆvar filesï¼‰è€Œéé‡å¤é…ç½®ã€‚
- CloudFormationçš„â€œå˜æ›´é›†â€ï¼ˆchange setsï¼‰ç›¸å½“äºTerraformçš„`terraform plan`åŠŸèƒ½â€”â€”åœ¨æ›´æ–°èµ„æºå †æ ˆå‰åŠ¡å¿…å…ˆåˆ›å»ºå˜æ›´é›†ã€‚
- å¦‚æœTerraformçš„HCLè¯­æ³•é™åˆ¶äº†ä½ çš„å¼€å‘éœ€æ±‚ï¼Œå¯ä»¥é€‰æ‹©ä½¿ç”¨Pulumiï¼ˆå®ƒæ”¯æŒå¾ªç¯ã€æ¡ä»¶è¯­å¥å’Œç±»å‹æ£€æŸ¥ç­‰åŠŸèƒ½ï¼‰ã€‚