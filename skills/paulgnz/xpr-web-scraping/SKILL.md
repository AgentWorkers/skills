---
name: web-scraping
description: 用于从网页中获取和提取数据的网络爬虫工具
---

## 网页抓取

您可以使用以下工具从网页中获取和提取数据：

**单页抓取：**
- `scrape_url` — 用于获取指定URL的文本内容及元数据（标题、描述、链接数量）
  - 默认使用 `format="text"` 格式：去除所有HTML标签
  - 使用 `format="markdown"` 可保留标题、链接、列表以及文本的加粗/斜体格式
  - 仅在需要原始HTML格式时使用 `format="html"` 格式

**链接提取：**
- `extract_links` — 从页面中提取所有链接（包括内部链接和外部链接），并指定链接的类型
  - 可通过 `pattern` 参数使用正则表达式进行过滤（例如 `".pdf$"` 可过滤出PDF链接）
  - 提取的链接会去重，并转换为绝对URL格式

**多页抓取：**
- `scrape_multiple` — 可同时并行获取最多10个URL的数据，用于比较或分析
  - 即使某个请求失败，其他请求仍会继续执行（使用 `Promise.allSettled` 确保所有请求都完成）

**最佳实践：**
- 对于内容提取，建议使用 `text` 格式；若需要保留页面结构，使用 `markdown` 格式
- 每分钟不要对同一域名进行超过5次抓取操作
- 结合 `store_deliverable` 功能将抓取到的数据保存为日志或证据文件
- 对于非常大的页面，抓取内容会被限制在5MB以内