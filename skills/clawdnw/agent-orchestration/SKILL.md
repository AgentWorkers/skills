---
name: agent-orchestration
version: 2.0.0
description: "掌握创建和管理子代理的技巧。编写有效的提示语句，监控正在运行的代理，并从每个结果中学习经验。这是 Hal Stack 的一部分 🦞"
author: halthelobster
---

# 代理编排 🦞  
**作者：Hal Labs** — Hal Stack 的一部分  

你的代理之所以失败，是因为你的提示语设计得糟糕。这个技巧可以解决这个问题。  

---

## 核心问题  

你并没有给出明确的指令；你只是在“祈求”模型按照你的意愿行事。  

大多数提示语都只是随意的、没有针对性的要求，就像扔进虚空中的愿望一样……  

你输入一些合理的内容，得到的结果却并不理想；你重新表述，结果依然不佳；你添加关键词，结果反而更糟……然后你把责任归咎于模型。  

但你没有意识到：**语言模型其实是一个基于模式匹配的生成工具**。它会根据你的输入，生成在统计上最有可能的输出结果。  

**模糊的输入 → 普通的输出**。这并不是因为模型愚蠢，而是因为当你没有提供具体的指令时，它只能生成最“常见”的结果罢了。  

**模型实际上只是按照你的要求进行了生成……只是你没有意识到自己提供的信息实在太少了而已。**  

---

## 对提示语的正确理解  

提示语并不是一种简单的请求，而是一份“契约”。这份契约必须明确回答四个不可协商的要素：  

| 要素        | 问题                                      |
|-------------|-----------------------------------------|
| **角色**       | 模型应该扮演什么角色？                         |
| **任务**       | 它必须完成的具体任务是什么？                       |
| **约束条件**    | 需要遵循哪些规则？                         |
| **输出结果**    | “完成”到底应该是什么样的？                     |

如果你忽略了任何一个要素，模型就会根据自己的假设来填补空白……而正是这些假设，导致了错误的输出结果。  

---

## 五层提示语结构  

有效的提示语遵循一种特定的结构，这与模型处理信息的方式是一致的：  

### 第一层：**角色**  
在这个对话中，模型应该扮演什么角色？  
它不是“万能的助手”，而是一个具有特定专业能力的实体……  

模型的“身份”非常重要。如果你忽略了这一点，它就会生成泛泛而谈的输出结果。  

### 第二层：**上下文**  
模型需要了解哪些信息，才能出色地完成任务？  
上下文必须满足以下条件：  
- **有序**：最重要的信息放在最前面；  
- **有针对性**：只包含相关的信息；  
- **有明确的标签**：区分哪些内容是规则、哪些是可以修改的、哪些是历史数据……  

**如果没有明确的标签，模型会将所有信息都视为同等重要的。**这会导致它误解你的意图。  

### 第三层：**任务**  
需要执行的具体操作是什么？  
不要只是简单地说“写点什么”，而应该给出明确的指令……  

你定义得越具体，模型执行得就越精准。  

### 第四层：**处理流程**  
**大多数提示语在这里就出问题了**。  
你只是要求模型生成结果，却忽略了结果的形成过程……  

❌ 错误的提示方式：  
✅ 正确的提示方式：  

**你需要的不是答案本身，而是答案的形成过程。**  
要像导演一样思考：你不是在要求一个场景的结果，而是在指导这个场景应该如何被构建。  

### 第五层：**输出结果**  
“完成”到底应该是什么样的？  
如果你没有明确说明，模型就会使用默认的格式来生成结果……  

**忽略任何一个层次，整个提示结构就会出问题；忽略两个层次，整个系统就会崩溃。**  

---

## 模型选择  
**提示语的通用性其实是个误区**。不同的模型有不同的专长。你不会对执行助理、设计师和后端开发人员使用完全相同的指令。  

| 模型类型 | 适用场景 | 需要注意的事项                |
|---------|---------|----------------------|
| Claude Opus | 复杂的推理、细腻的写作、长篇文本处理 | 计算成本较高，可能输出冗长         |
| Claude Sonnet | 平衡性较好的任务、代码编写、数据分析 | 相较于 Opus，创造力稍逊             |
| GPT-4 | 广泛的知识储备、结构化的输出 | 可能会过于谄媚                 |
| 小型模型   | 快速的任务、简单的查询       | 推理能力有限                 |

**根据模型的特点来定制提示语：**  
- 有些模型更喜欢结构化的语言；  
- 有些模型需要明确的步骤顺序；  
- 有些模型无法处理冗长的指令；  
- 有些模型擅长分析，但在创造力方面表现不佳……  

**编写针对特定模型的提示语的人，总是会比那些“有创意”的人表现得更好。**  

---

## 约束条件就是指令  
**模糊的指令并不意味着灵活性……而是缺乏勇气。**  
你之所以犹豫不决，是因为害怕具体化指令会带来风险……但模型并不能读取你的想法。  

**约束条件并不是限制，而是明确的指令。**  

**每次对话都是从零开始的**；模型并没有之前与你合作的经验作为参考……**一致性来源于明确的指令，而非模型自身的记忆。**  

---

## 规范化的文档编写  
如果你没有相关的文档，那你就是在赌博。  

| 文档类型    | 用途                        |
|-----------|---------------------------|
| PRD       | 我们正在构建什么，以及为什么这样做        |
| 设计系统文档 | 视觉化的规则和组件结构           |
| 约束条件文档 | 绝对不能改变的内容                |
| 上下文文档 | 当前的状态和历史记录             |

**规则：**在提示语中引用这些文档。**  

**没有明确的指导，模型就会把一切都视为可变的……**  

> “好的提示语并不是写出更好的句子，而是让模型基于现实来生成结果。”  

---

## 完整的提示语模板  

---

## Ralph 模式  
**适用于那些初次尝试就可能失败的任务：**  
（具体内容略……）  

**使用场景：**  
- 需要多个组件协同完成的任务；  
- 集成工作；  
- 任何初次尝试成功率较低的任务……  

---

## 代理跟踪  
**每个生成的代理都会被记录在案，不会被遗漏。**  
请维护 `notes/areas/active-agents.md` 文件：  

**定期检查代理的状态：**  
（具体操作略……）  

---

## 学习循环  
每个代理的执行结果都可以作为数据被收集起来。  
请维护 `LEARNINGS.md` 文件：  

---

## 角色库  
可以创建可复用的角色定义：  

---

## 快速参考  
### 四个不可协商的要素：  
1. **角色**：模型应该扮演什么角色？  
2. **任务**：它必须完成的具体任务是什么？  
3. **约束条件**：需要遵循哪些规则？  
4. **输出结果**：“完成”应该是什么样的？  

### 五层提示语结构：  
1. **角色**：模型的具体角色和专长；  
2. **上下文**：有序、有针对性、有明确标签的背景信息；  
3. **任务**：具体且可衡量的任务目标；  
4. **处理流程**：完成任务的具体方法（这一点常常被忽视！）；  
5. **输出结果**：输出结果的格式要求。  

### 提示语编写前的检查清单：  
- 角色是否已经明确？  
- 上下文是否已经标注清楚（包括规则、状态、历史信息）？  
- 任务是否具体且可衡量？  
- 处理流程是否描述清楚（而不仅仅是输出结果）？  
- 用户需求是否已经明确？  
- 输出格式是否已经确定？  
- 错误处理机制是否已经考虑？  
- 是否已经记录在跟踪文件中？  

---

## 最后的真相  
“AI 无法满足我的需求”与“获得出色的结果”之间的差距，并不在于模型的智能程度或访问权限……  
**区别在于：**  
有些人把提示语当作普通的对话来处理；而有些人则把它当作系统指令来精心设计。  

模型的表现取决于你提供的指令的严谨程度：  
- 模糊的输入 → 普通的输出；  
- 结构化的输入 → 结构化的输出；  
- 清晰的思考 → 明确的结果。  

你不需要变得更聪明，只需要表达得更清晰而已。  

**清晰的表达是一种系统能力，而非天赋。**  

---

*Hal Stack 的一部分 🦞*  

**如果你有改进提示语的想法，可以发送邮件至：halthelobster@protonmail.com**  

---

**“你并没有给出明确的指令，你只是在祈求模型按照你的意愿行事……**  
**是时候开始认真设计提示语了。”**