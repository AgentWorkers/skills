---
name: increment-quality-judge-v2
description: 基于大语言模型（LLM）的智能质量评估机制，采用“LLM作为评判者”的模式，并结合BMAD风险评分系统以及正式的质量审查流程。该机制可用于评估软件的增量变更需求（increment specs）、判断任务完成情况，或做出质量审查决策（通过/存在问题/失败）。通过清晰的逻辑推理过程，确保评估过程的透明性和公正性。
allowed-tools: Read, Grep, Glob
---

# increment-quality-judge v2.0

## LLM（大型语言模型）作为评估工具的实现

本版本采用 **LLM作为评估工具** 的模式，利用人工智能技术进行质量评估。这是一种成熟的人工智能/机器学习评估方法，其中LLM通过逻辑推理、BMAD风险评分以及正式的质量判断（通过/有问题/失败）来评估输出结果。

## LLM作为评估工具：简介

**LLM作为评估工具（LLM-as-Judge, LaaJ）** 是一种被广泛认可的人工智能/机器学习评估方法，它利用大型语言模型通过结构化的推理过程来进行质量评估。

### LLM作为评估工具的优势：
- **一致性**：评估标准统一，且无需人工疲劳；
- **逻辑清晰**：能够清晰地解释问题产生的原因；
- **可扩展性**：评估速度极快（仅需几秒钟），而人工审核可能需要数小时；
- **行业标准**：OpenAI、Anthropic、Google等公司都在使用这种方法进行AI评估。

## 参考资料：
- “Judging LLM-as-a-Judge”（NeurIPS 2023会议论文）
- LMSYS聊天机器人竞赛的评估方法论
- AlpacaEval、MT-Bench评估框架

**重要提示：** 这只是一个 **技能**（Skill），而非一个独立的代理（Agent）。**请勿尝试通过任务工具来启动该技能**。**

该技能会自动在您讨论质量评估时被激活。具体的执行操作由命令行界面（CLI）负责完成。

**为什么不使用代理？** 因为如果同时存在名为 `increment-quality-judge-v2` 的技能和代理，可能会导致Claude在识别代理类型时产生混淆。仅使用技能的方式可以避免这种问题。

## v2.0的新功能：
1. **风险评估维度**：引入了基于BMAD模型的风险评分机制（0-10分）；
2. **正式的质量判断**：提供了明确的通过/有问题/失败的结果；
3. **非功能性需求检查**：涵盖了性能、安全、可扩展性等方面的评估；
4. **改进的输出格式**：输出结果包括问题点、建议以及相应的缓解措施；
5. **新增维度**：在原有的6个评估维度基础上增加了“风险”维度。

## 使用场景
- 当您执行 `/qa {increment-id}` 命令时，该技能会自动启动；
- `/qa {increment-id} --pre` 用于预实施阶段的质量检查；
- `/qa {increment-id} --gate` 用于正式的质量判断；
- 也可以通过自然语言命令（如 “assess quality of increment 0001”）来调用该技能。

## 关键术语：
- 验证质量（Validate quality）
- 质量检查（Quality check）
- 评估增量（Evaluate increment）
- 规范审查（Spec review）
- 风险评估（Risk assessment）
- 质量判断（Quality gate）

## 评估维度（共7个，原为6个）

## 风险评估（基于BMAD模型，新增！）

### 风险评分公式

### 风险分类
1. **安全风险**：
   - OWASP十大常见漏洞
   - 数据泄露、身份验证问题、授权问题
   - 加密机制缺陷
2. **技术风险**：
   - 架构复杂性、可扩展性瓶颈
   - 性能问题、技术债务（技术上的遗留问题）
3. **实施风险**：
   - 时间紧迫、外部依赖问题
   - 技术复杂性过高
4. **运营风险**：
   - 监控机制缺失、维护困难
   - 文档编写不完善

### 风险评估提示（用于指导用户提供评估信息）

## 正式的质量判断结果（新增！）

### 判断逻辑

### 输出示例

## 工作流程集成
- **快速模式（默认设置）**
- **预实施模式**
- **质量判断模式**

## 评分算法优化
- **步骤1：维度评估（7个维度）**：针对每个维度（包括新增的风险维度）使用逻辑推理进行评估；
- **步骤2：加权总分计算（新权重设置）**；
- **步骤3：质量判断**：根据评估结果做出正式的通过/有问题/失败的决定。

## 成本估算（基于每个增量文件）
- 文件长度：
  - 短文件（<100行）：约2,500个词元（约0.025美元）
  - 中等长度文件（100-250行）：约3,500个词元（约0.035美元）
  - 长文件（>250行）：约5,000个词元（约0.050美元）
- 与v1.0相比，成本增加了25%（因为新增了风险评估维度）。

## 配置选项
- 允许用户配置评估的详细程度。

## 从v1.0升级到v2.0的流程：
- **v1.0的评估维度**：清晰度、可测试性、完整性、可行性、可维护性、边缘情况；
- **v2.0的新增维度**：风险评估；
- 权重根据新维度进行了调整；
- 增加了正式的质量判断功能；
- 兼容性保障：如果启用了风险评估功能，系统会自动将v1.0的技能升级到v2.0版本；
- 现有评分结果会自动按照新权重进行重新计算；
- 用户也可以在配置中禁用风险评估功能，恢复到v1.0的行为。

## 最佳实践：
- **尽早且频繁地使用该技能**：建议在实施前使用 `--pre` 模式；
- **立即解决存在的问题**：如果评估结果为“失败”，请立即修复相关问题；
- **在发布前处理存在的问题**：将存在的问题列为需要修复的事项；
- **根据风险评分优先处理问题**：优先解决关键风险；
- **将评估结果导出到任务列表中**：将问题和建议转化为可执行的操作任务。

## 功能限制
- **注意事项**：
  - 该工具无法理解特定领域的合规性要求（如HIPAA、PCI-DSS）；
  - 无法通过实际代码库验证技术的可行性；
  - 无法替代人类的专业判断和安全审计；
  - 无法在没有历史数据的情况下预测风险发生的概率。

## 功能优势
- **能够**：
  - 发现语言表述模糊或不明确的地方；
  - 识别缺失的安全相关问题（基于OWASP标准）；
  - 指出无法通过测试的验收标准；
  - 建议最佳的行业实践；
  - 标出遗漏的边缘情况；
  - **系统化地进行风险评估（基于BMAD模型）；
  - 提供正式的质量判断结果。

## 总结
**increment-quality-judge v2.0** 提供了全面的风险评估和正式的质量判断功能：
- **风险评估**：基于BMAD模型的风险评分（0-10分）；
- **质量判断**：提供明确的通过/有问题/失败的结果；
- **新增的7个评估维度**；
- **非功能性需求检查**；
- **改进的输出格式**；
- **遵循LLM作为评估工具的最佳实践**。

**适用场景**：
- 当您需要在实施或发布前进行全面的质量评估时，该工具是理想的选择。

**不适用场景**：
- 在迭代速度较快、词元预算有限，或者功能简单、仅需要基于规则进行验证的情况下，可以跳过该工具的使用。

---

**版本号**：2.0.0  
**相关命令**：/sw:qa  
**相关组件**：QAOrchestrator代理