---
name: "pandas-construction-analysis"
description: "ä¸€ä¸ªå…¨é¢çš„Pandaså·¥å…·åŒ…ï¼Œç”¨äºå»ºç­‘æ•°æ®åˆ†æã€‚æ”¯æŒè¿‡æ»¤ã€åˆ†ç»„ã€æ±‡æ€»BIMå…ƒç´ ï¼Œè®¡ç®—æ•°é‡ï¼Œåˆå¹¶æ•°æ®é›†ï¼Œå¹¶ä»ç»“æ„åŒ–çš„å»ºç­‘æ•°æ®ä¸­ç”ŸæˆæŠ¥å‘Šã€‚"
homepage: "https://datadrivenconstruction.io"
metadata: {"openclaw": {"emoji": "ğŸ¼", "os": ["darwin", "linux", "win32"], "homepage": "https://datadrivenconstruction.io", "requires": {"bins": ["python3"]}}}
---# Pandasåœ¨å»ºç­‘æ•°æ®åˆ†æä¸­çš„åº”ç”¨

## æ¦‚è¿°

æœ¬æŠ€èƒ½åŸºäºDDCæ–¹æ³•è®ºï¼ˆç¬¬2.3ç« ï¼‰ï¼Œæä¾›äº†ä½¿ç”¨Pandasè¿›è¡Œå»ºç­‘æ•°æ®å¤„ç†çš„å…¨é¢æ“ä½œã€‚Pandaså ªç§°æ•°æ®åˆ†æå¸ˆçš„â€œç‘å£«å†›åˆ€â€â€”â€”èƒ½å¤Ÿå¤„ç†ä»ç®€å•çš„æ•°æ®è¿‡æ»¤åˆ°å¯¹æ•°ç™¾ä¸‡è¡Œæ•°æ®è¿›è¡Œå¤æ‚èšåˆçš„å„ç§ä»»åŠ¡ã€‚

**å‚è€ƒä¹¦ç±**ï¼šã€ŠPandas DataFrameä¸LLM ChatGPTã€‹  
> â€œé€šè¿‡ä½¿ç”¨Pandasï¼Œæ‚¨å¯ä»¥ç®¡ç†å’Œåˆ†æè¿œè¶…Excelå¤„ç†èƒ½åŠ›çš„æ•°æ®é›†ã€‚è™½ç„¶Excelæœ€å¤šåªèƒ½å¤„ç†100ä¸‡è¡Œæ•°æ®ï¼Œä½†Pandaså¯ä»¥è½»æ¾å¤„ç†åŒ…å«æ•°åƒä¸‡è¡Œæ•°æ®çš„æ•°æ®é›†ã€‚â€  
â€”â€”DDCä¹¦ç±ï¼Œç¬¬2.3ç« 

## å¿«é€Ÿå…¥é—¨

```python
import pandas as pd

# Read construction data
df = pd.read_excel("bim_export.xlsx")

# Basic operations
print(df.head())           # First 5 rows
print(df.info())           # Column types and memory
print(df.describe())       # Statistics for numeric columns

# Filter structural elements
structural = df[df['Category'] == 'Structural']

# Calculate total volume
total_volume = df['Volume'].sum()
print(f"Total volume: {total_volume:.2f} mÂ³")
```

## DataFrameåŸºç¡€

### åˆ›å»ºDataFrame

```python
import pandas as pd

# From dictionary (construction elements)
elements = pd.DataFrame({
    'ElementId': ['E001', 'E002', 'E003', 'E004'],
    'Category': ['Wall', 'Floor', 'Wall', 'Column'],
    'Material': ['Concrete', 'Concrete', 'Brick', 'Steel'],
    'Volume_m3': [45.5, 120.0, 32.0, 8.5],
    'Level': ['Level 1', 'Level 1', 'Level 2', 'Level 1']
})

# From CSV
df_csv = pd.read_csv("construction_data.csv")

# From Excel
df_excel = pd.read_excel("project_data.xlsx", sheet_name="Elements")

# From multiple Excel sheets
all_sheets = pd.read_excel("project.xlsx", sheet_name=None)  # Dict of DataFrames
```

### å»ºç­‘è¡Œä¸šä¸­çš„æ•°æ®ç±»å‹

```python
# Common data types for construction
df = pd.DataFrame({
    'element_id': pd.Series(['W001', 'W002'], dtype='string'),
    'quantity': pd.Series([10, 20], dtype='int64'),
    'volume': pd.Series([45.5, 32.0], dtype='float64'),
    'is_structural': pd.Series([True, False], dtype='bool'),
    'created_date': pd.to_datetime(['2024-01-15', '2024-01-16']),
    'category': pd.Categorical(['Wall', 'Slab'])
})

# Check data types
print(df.dtypes)

# Convert types
df['quantity'] = df['quantity'].astype('float64')
df['volume'] = pd.to_numeric(df['volume'], errors='coerce')
```

## è¿‡æ»¤ä¸é€‰æ‹©

### åŸºæœ¬è¿‡æ»¤

```python
# Single condition
walls = df[df['Category'] == 'Wall']

# Multiple conditions (AND)
large_concrete = df[(df['Material'] == 'Concrete') & (df['Volume_m3'] > 50)]

# Multiple conditions (OR)
walls_or_floors = df[(df['Category'] == 'Wall') | (df['Category'] == 'Floor')]

# Using isin for multiple values
structural = df[df['Category'].isin(['Wall', 'Column', 'Beam', 'Foundation'])]

# String contains
insulated = df[df['Description'].str.contains('insulated', case=False, na=False)]

# Null value filtering
incomplete = df[df['Cost'].isna()]
complete = df[df['Cost'].notna()]
```

### é«˜çº§é€‰æ‹©

```python
# Select columns
volumes = df[['ElementId', 'Category', 'Volume_m3']]

# Query syntax (SQL-like)
result = df.query("Category == 'Wall' and Volume_m3 > 30")

# Loc and iloc
specific_row = df.loc[0]                    # By label
range_rows = df.iloc[0:10]                  # By position
specific_cell = df.loc[0, 'Volume_m3']      # Row and column
subset = df.loc[0:5, ['Category', 'Volume_m3']]  # Range with columns
```

## åˆ†ç»„ä¸èšåˆ

### GroupByæ“ä½œ

```python
# Basic groupby
by_category = df.groupby('Category')['Volume_m3'].sum()

# Multiple aggregations
summary = df.groupby('Category').agg({
    'Volume_m3': ['sum', 'mean', 'count'],
    'Cost': ['sum', 'mean']
})

# Named aggregations (cleaner output)
summary = df.groupby('Category').agg(
    total_volume=('Volume_m3', 'sum'),
    avg_volume=('Volume_m3', 'mean'),
    element_count=('ElementId', 'count'),
    total_cost=('Cost', 'sum')
).reset_index()

# Multiple grouping columns
by_level_cat = df.groupby(['Level', 'Category']).agg({
    'Volume_m3': 'sum',
    'Cost': 'sum'
}).reset_index()
```

### æ•°æ®é€è§†è¡¨

```python
# Create pivot table
pivot = pd.pivot_table(
    df,
    values='Volume_m3',
    index='Level',
    columns='Category',
    aggfunc='sum',
    fill_value=0,
    margins=True,           # Add totals
    margins_name='Total'
)

# Multiple values
pivot_detailed = pd.pivot_table(
    df,
    values=['Volume_m3', 'Cost'],
    index='Level',
    columns='Category',
    aggfunc={'Volume_m3': 'sum', 'Cost': 'mean'}
)
```

## æ•°æ®è½¬æ¢

### æ·»åŠ è®¡ç®—åˆ—

```python
# Simple calculation
df['Cost_Total'] = df['Volume_m3'] * df['Unit_Price']

# Conditional column
df['Size_Category'] = df['Volume_m3'].apply(
    lambda x: 'Large' if x > 50 else ('Medium' if x > 20 else 'Small')
)

# Using np.where for binary conditions
import numpy as np
df['Is_Large'] = np.where(df['Volume_m3'] > 50, True, False)

# Using cut for binning
df['Volume_Bin'] = pd.cut(
    df['Volume_m3'],
    bins=[0, 10, 50, 100, float('inf')],
    labels=['XS', 'S', 'M', 'L']
)
```

### å­—ç¬¦ä¸²æ“ä½œ

```python
# Extract from strings
df['Level_Number'] = df['Level'].str.extract(r'(\d+)').astype(int)

# Split and expand
df[['Building', 'Floor']] = df['Location'].str.split('-', expand=True)

# Clean strings
df['Category'] = df['Category'].str.strip().str.lower().str.title()

# Replace values
df['Material'] = df['Material'].str.replace('Reinforced Concrete', 'RC')
```

### æ—¥æœŸæ“ä½œ

```python
# Parse dates
df['Start_Date'] = pd.to_datetime(df['Start_Date'])

# Extract components
df['Year'] = df['Start_Date'].dt.year
df['Month'] = df['Start_Date'].dt.month
df['Week'] = df['Start_Date'].dt.isocalendar().week
df['DayOfWeek'] = df['Start_Date'].dt.day_name()

# Calculate duration
df['Duration_Days'] = (df['End_Date'] - df['Start_Date']).dt.days

# Filter by date range
recent = df[df['Start_Date'] >= '2024-01-01']
```

## åˆå¹¶ä¸è¿æ¥

### åˆå¹¶DataFrame

```python
# Elements data
elements = pd.DataFrame({
    'ElementId': ['E001', 'E002', 'E003'],
    'Category': ['Wall', 'Floor', 'Column'],
    'Volume_m3': [45.5, 120.0, 8.5]
})

# Unit prices
prices = pd.DataFrame({
    'Category': ['Wall', 'Floor', 'Column', 'Beam'],
    'Unit_Price': [150, 80, 450, 200]
})

# Inner join (only matching)
merged = elements.merge(prices, on='Category', how='inner')

# Left join (keep all elements)
merged = elements.merge(prices, on='Category', how='left')

# Join on different column names
result = df1.merge(df2, left_on='elem_id', right_on='ElementId')
```

### è¿æ¥DataFrame

```python
# Vertical concatenation (stacking)
all_floors = pd.concat([floor1_df, floor2_df, floor3_df], ignore_index=True)

# Horizontal concatenation
combined = pd.concat([quantities, costs, schedule], axis=1)

# Append new rows
new_elements = pd.DataFrame({'ElementId': ['E004'], 'Category': ['Beam']})
df = pd.concat([df, new_elements], ignore_index=True)
```

## å»ºç­‘è¡Œä¸šç‰¹æœ‰çš„åˆ†æ

### æ•°é‡ç»Ÿè®¡ï¼ˆQTOï¼‰

```python
def generate_qto_report(df):
    """Generate Quantity Take-Off summary by category"""
    qto = df.groupby(['Category', 'Material']).agg(
        count=('ElementId', 'count'),
        total_volume=('Volume_m3', 'sum'),
        total_area=('Area_m2', 'sum'),
        avg_volume=('Volume_m3', 'mean')
    ).round(2)

    # Add percentage column
    qto['volume_pct'] = (qto['total_volume'] /
                          qto['total_volume'].sum() * 100).round(1)

    return qto.sort_values('total_volume', ascending=False)

# Usage
qto_report = generate_qto_report(df)
qto_report.to_excel("qto_report.xlsx")
```

### æˆæœ¬ä¼°ç®—

```python
def calculate_project_cost(elements_df, prices_df, markup=0.15):
    """Calculate total project cost with markup"""
    # Merge with prices
    df = elements_df.merge(prices_df, on='Category', how='left')

    # Calculate base cost
    df['Base_Cost'] = df['Volume_m3'] * df['Unit_Price']

    # Apply markup
    df['Total_Cost'] = df['Base_Cost'] * (1 + markup)

    # Summary by category
    summary = df.groupby('Category').agg(
        volume=('Volume_m3', 'sum'),
        base_cost=('Base_Cost', 'sum'),
        total_cost=('Total_Cost', 'sum')
    ).round(2)

    return df, summary, summary['total_cost'].sum()

# Usage
detailed, summary, total = calculate_project_cost(elements, prices)
print(f"Project Total: ${total:,.2f}")
```

### ææ–™æ±‡æ€»

```python
def material_summary(df):
    """Summarize materials across project"""
    summary = df.groupby('Material').agg({
        'Volume_m3': 'sum',
        'Weight_kg': 'sum',
        'ElementId': 'nunique'
    }).rename(columns={'ElementId': 'Element_Count'})

    summary['Volume_Pct'] = (summary['Volume_m3'] /
                              summary['Volume_m3'].sum() * 100).round(1)

    return summary.sort_values('Volume_m3', ascending=False)
```

### åˆ†å±‚åˆ†æ

```python
def analyze_by_level(df):
    """Analyze construction quantities by building level"""
    level_summary = df.pivot_table(
        values=['Volume_m3', 'Cost'],
        index='Level',
        columns='Category',
        aggfunc='sum',
        fill_value=0
    )

    level_summary['Total_Volume'] = level_summary['Volume_m3'].sum(axis=1)
    level_summary['Total_Cost'] = level_summary['Cost'].sum(axis=1)

    return level_summary
```

## æ•°æ®å¯¼å‡º

### å¯¼å‡ºä¸ºåŒ…å«å¤šä¸ªå·¥ä½œè¡¨çš„Excelæ–‡ä»¶

```python
def export_to_excel_formatted(df, summary, filepath):
    """Export with multiple sheets"""
    with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
        df.to_excel(writer, sheet_name='Details', index=False)
        summary.to_excel(writer, sheet_name='Summary')

        pivot = pd.pivot_table(df, values='Volume_m3',
                               index='Level', columns='Category')
        pivot.to_excel(writer, sheet_name='By_Level')

# Usage
export_to_excel_formatted(elements, qto_summary, "project_report.xlsx")
```

### å¯¼å‡ºä¸ºCSVæ–‡ä»¶

```python
# Basic export
df.to_csv("output.csv", index=False)

# With encoding for special characters
df.to_csv("output.csv", index=False, encoding='utf-8-sig')

# Specific columns
df[['ElementId', 'Category', 'Volume_m3']].to_csv("volumes.csv", index=False)
```

## æ€§èƒ½ä¼˜åŒ–æŠ€å·§

```python
# Use categories for string columns with few unique values
df['Category'] = df['Category'].astype('category')

# Read only needed columns
df = pd.read_csv("large_file.csv", usecols=['ElementId', 'Category', 'Volume'])

# Use chunking for very large files
chunks = pd.read_csv("huge_file.csv", chunksize=100000)
result = pd.concat([chunk[chunk['Category'] == 'Wall'] for chunk in chunks])

# Check memory usage
print(df.memory_usage(deep=True).sum() / 1024**2, "MB")
```

## å¿«é€Ÿå‚è€ƒ

| æ“ä½œ          | ä»£ç                 |
|---------------|-------------------|
| è¯»å–Excelæ–‡ä»¶     | `pd.read_excel("file.xlsx")`    |
| è¯»å–CSVæ–‡ä»¶     | `pd.read_csv("file.csv")`    |
| è¿‡æ»¤è¡Œ         | `df[df['Column'] == 'Value']`    |
| é€‰æ‹©åˆ—         | `df[['Col1', 'Col2']]`     |
| åˆ†ç»„å¹¶æ±‚å’Œ     | `df.groupby('Cat')['Vol'].sum()`   |
| æ•°æ®é€è§†è¡¨       | `pd.pivot_table(df, values='Vol', index='Level')` |
| åˆå¹¶DataFrame     | `df1.merge(df2, on='key')`     |
| æ·»åŠ æ–°åˆ—       | `df['New'] = df['A'] * df['B']`    |
| å¯¼å‡ºä¸ºExcelæ–‡ä»¶   | `df.to_excel("out.xlsx", index=False)` |

## èµ„æº

- **ä¹¦ç±**ï¼šArtem Boikoæ‰€è‘—çš„ã€ŠData-Driven Constructionã€‹ï¼Œç¬¬2.3ç«   
- **ç½‘ç«™**ï¼šhttps://datadrivenconstruction.io  
- **Pandasæ–‡æ¡£**ï¼šhttps://pandas.pydata.org/docs/

## ä¸‹ä¸€æ­¥

- å¯å‚è€ƒ`llm-data-automation`ä»¥äº†è§£å¦‚ä½•åˆ©ç”¨AIç”ŸæˆPandasä»£ç   
- å¯å‚è€ƒ`qto-report`ä»¥è·å–ä¸“é—¨çš„QTOè®¡ç®—å·¥å…·  
- å¯å‚è€ƒ`cost-estimation-resource`ä»¥è·å–è¯¦ç»†çš„æˆæœ¬è®¡ç®—æ–¹æ³•